{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmgbfqAKOsxR"
   },
   "source": [
    "# Plan of Action"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_kTFrNNPU7wP",
    "ExecuteTime": {
     "end_time": "2025-04-08T15:00:03.555253Z",
     "start_time": "2025-04-08T15:00:03.533281Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import importlib\n",
    "import pandas\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to sys.path\n",
    "parent_dir = Path(\"..\").resolve()\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import common_utils\n",
    "importlib.reload(common_utils)\n",
    "from common_utils import *\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "np.random.seed(69)\n",
    "tf.random.set_seed(69)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5P0vu49KbWXH"
   },
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Yu50xj5jU8I6",
    "ExecuteTime": {
     "end_time": "2025-04-08T14:55:38.911194Z",
     "start_time": "2025-04-08T14:55:38.801628Z"
    }
   },
   "source": [
    "# normal data\n",
    "image_paths_csv = pd.read_csv(\"./processed_data/image_paths_7_classes.csv\")\n",
    "#aug data\n",
    "image_paths_csv_aug = pd.read_csv(\"./processed_data/image_paths_7_classes_aug.csv\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:55:38.922277Z",
     "start_time": "2025-04-08T14:55:38.912447Z"
    }
   },
   "cell_type": "code",
   "source": "image_paths_csv",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                    path  age  age_bin         age_bin_label\n",
       "0     ../raw_data2/face_age/001/1000.png    1        0  Infant/Toddler (1–4)\n",
       "1     ../raw_data2/face_age/001/1018.png    1        0  Infant/Toddler (1–4)\n",
       "2     ../raw_data2/face_age/001/1030.png    1        0  Infant/Toddler (1–4)\n",
       "3     ../raw_data2/face_age/001/1062.png    1        0  Infant/Toddler (1–4)\n",
       "4     ../raw_data2/face_age/001/1068.png    1        0  Infant/Toddler (1–4)\n",
       "...                                  ...  ...      ...                   ...\n",
       "9567  ../raw_data2/face_age/100/2694.png  100        6         Seniors (75+)\n",
       "9568  ../raw_data2/face_age/100/6408.png  100        6         Seniors (75+)\n",
       "9569  ../raw_data2/face_age/101/1554.png  101        6         Seniors (75+)\n",
       "9570  ../raw_data2/face_age/110/3906.png  110        6         Seniors (75+)\n",
       "9571  ../raw_data2/face_age/110/9628.png  110        6         Seniors (75+)\n",
       "\n",
       "[9572 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>age</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>age_bin_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../raw_data2/face_age/001/1000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Infant/Toddler (1–4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../raw_data2/face_age/001/1018.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Infant/Toddler (1–4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../raw_data2/face_age/001/1030.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Infant/Toddler (1–4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../raw_data2/face_age/001/1062.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Infant/Toddler (1–4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../raw_data2/face_age/001/1068.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Infant/Toddler (1–4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9567</th>\n",
       "      <td>../raw_data2/face_age/100/2694.png</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>Seniors (75+)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9568</th>\n",
       "      <td>../raw_data2/face_age/100/6408.png</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>Seniors (75+)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9569</th>\n",
       "      <td>../raw_data2/face_age/101/1554.png</td>\n",
       "      <td>101</td>\n",
       "      <td>6</td>\n",
       "      <td>Seniors (75+)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9570</th>\n",
       "      <td>../raw_data2/face_age/110/3906.png</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>Seniors (75+)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9571</th>\n",
       "      <td>../raw_data2/face_age/110/9628.png</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>Seniors (75+)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9572 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Organize Dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:55:38.996029Z",
     "start_time": "2025-04-08T14:55:38.923627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "data= load_tensors_from_paths_csv(paths_csv=image_paths_csv)\n",
    "aug_data=load_tensors_from_paths_csv(paths_csv=image_paths_csv_aug)\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Image Greyscale Function"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN Architecture"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Batch 1: config_1\n",
    "A bunch of options based on the suggestions in the assignment.\n",
    "Best models: \\\n",
    "    {\"name\": \"B2_deep\", \"conv_filters\": [32, 64, 128, 256, 512]}, \\ \n",
    "    {\"name\": \"K1_k7_deep\", \"kernel_size\": 7, \"conv_filters\": [64, 128, 256]} \\\n",
    "    {\"name\": \"E4_epochs_300\", \"epochs\": 300}, \\\n",
    "    {\"name\": \"J2_dense_256_128\", \"dense_units\": [256, 128]}, acc: 0.4096 \\\n",
    "    {\"name\": \"A3_relu_k5\", \"activation\": \"relu\", \"kernel_size\": 5}, \\\n",
    "Worst model: \\\n",
    "    {\"name\": \"I1_deep_selu\", \"activation\": \"selu\", \"conv_filters\": [64, 128, 256, 512]}, \\\n",
    "    {\"name\": \"I2_shallow_tanh\", \"activation\": \"tanh\", \"conv_filters\": [16, 32]}, \\\n",
    "    {\"name\": \"A4_selu_k7\", \"activation\": \"selu\", \"kernel_size\": 7}, \\\n",
    "    {\"name\": \"A2_tanh_k3\", \"activation\": \"tanh\", \"kernel_size\": 3}, \\\n",
    "    {\"name\": \"B1_shallow\", \"conv_filters\": [32, 64]}, \\\n",
    "    \n",
    "Batch 2: config_2 \\\n",
    "Tried fixing the bad, improving the best \\\n",
    "Best models: \\\n",
    "{\"name\": \"A3B_relu_k5_improved\", \"activation\": \"relu\",\"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256], \"dropout_rate\": 0.5}, \\\n",
    "{\"name\": \"B2B_deep_bn\", \"conv_filters\": [32, 64, 128, 256, 512], \"activation\": \"relu\", \"dropout_rate\": 0.5, \"batch_norm\": True}, \\\n",
    "{\"name\": \"A4B_relu_k7\", \"activation\": \"relu\", \"kernel_size\": 7, \"conv_filters\": [32, 64, 128]},\n",
    "\n",
    "Bad models: \\\n",
    "{\"name\": \"I2B_mid_relu\", \"activation\": \"relu\", \"conv_filters\": [32, 64, 128]}, \\\n",
    "{\"name\": \"J2B_dense_256_128\", \"dense_units\": [256, 128], \"activation\": \"relu\", \"dropout_rate\": 0.5, \n",
    " \"batch_norm_dense\": True}, acc: 0.3898 \\\n",
    "{\"name\": \"E4B_epochs_300\", \"epochs\": 300, \"dropout_rate\": 0.5, \"lr_schedule\": \"reduce_on_plateau\"}, didn't improve much  \\\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:55:39.044243Z",
     "start_time": "2025-04-08T14:55:38.996976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# first batch, a bunch of random-ish models\n",
    "config_1 = [\n",
    "    {\"name\": \"baseline\"},\n",
    "    \n",
    "    {\"name\": \"A1_relu_k3\", \"activation\": \"relu\", \"kernel_size\": 3},\n",
    "    {\"name\": \"A3_relu_k5\", \"activation\": \"relu\", \"kernel_size\": 5},\n",
    "    \n",
    "    {\"name\": \"B2_deep\", \"conv_filters\": [32, 64, 128, 256, 512]},\n",
    "    \n",
    "    {\"name\": \"J1_dense_512\", \"dense_units\": [512]},\n",
    "    {\"name\": \"J2_dense_256_128\", \"dense_units\": [256, 128]},\n",
    "    \n",
    "    {\"name\": \"E1_dense1\", \"dense_units\": [128]},\n",
    "    {\"name\": \"E2_dense3\", \"dense_units\": [256, 128, 64]},\n",
    "    \n",
    "      # Grayscale (1-channel) input\n",
    "    {\"name\": \"F1_gray\", \"channels\": 1},\n",
    "    {\"name\": \"F2_gray_k5\", \"channels\": 1, \"kernel_size\": 5},\n",
    "    {\"name\": \"F3_gray_deep\", \"channels\": 1, \"conv_filters\": [32, 64, 128, 256]},\n",
    "    {\"name\": \"F4_gray_dense2\", \"channels\": 1, \"dense_units\": [256, 128]},\n",
    "\n",
    "    \n",
    "    {\"name\": \"H1_dropout_0.3\", \"dropout_rate\": 0.3},\n",
    "    {\"name\": \"H2_dropout_0.7\", \"dropout_rate\": 0.7},\n",
    "    \n",
    "        # Batch size variations\n",
    "    {\"name\": \"B3_batch_128\", \"batch_size\": 128},\n",
    "    {\"name\": \"B4_batch_64\", \"batch_size\": 64},\n",
    "    \n",
    "        # Epoch variations\n",
    "    {\"name\": \"E1_epochs_60\", \"epochs\": 60},\n",
    "    {\"name\": \"E2_epochs_180\", \"epochs\": 180},\n",
    "    {\"name\": \"E3_epochs_240\", \"epochs\": 240},\n",
    "    {\"name\": \"E4_epochs_300\", \"epochs\": 300},\n",
    "\n",
    "    {\"name\": \"K1_k7_deep\", \"kernel_size\": 7, \"conv_filters\": [64, 128, 256]}\n",
    "    ]\n",
    "\n",
    "# second batch, improve on best, fix worse\n",
    "config_2 = [\n",
    "    {\"name\": \"baseline\"},\n",
    "    # Improved version of \"B2_deep\"\n",
    "    {\"name\": \"B2B_deep_bn\", \"conv_filters\": [32, 64, 128, 256, 512], \"activation\": \"relu\", \"dropout_rate\": 0.5, \"batch_norm\": True},\n",
    "    # Improved version of \"K1_k7_deep\"\n",
    "    {\"name\": \"K1B_k7_deep_bn\", \"kernel_size\": 7, \"conv_filters\": [64, 128, 256, 512], \"activation\": \"relu\", \"dropout_rate\": 0.4, \"batch_norm\": True},\n",
    "    # Improved version of \"E4_epochs_300\"\n",
    "    {\"name\": \"E4B_epochs_300\", \"epochs\": 300, \"dropout_rate\": 0.5, \"lr_schedule\": \"reduce_on_plateau\"},\n",
    "    # Improved version of \"J2_dense_256_128\"\n",
    "    {\"name\": \"J2B_dense_256_128\", \"dense_units\": [256, 128], \"activation\": \"relu\", \"dropout_rate\": 0.5, \"batch_norm_dense\": True},\n",
    "    # Improved version of \"A3_relu_k5\"\n",
    "    {\"name\": \"A3B_relu_k5_improved\", \"activation\": \"relu\",\"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256], \"dropout_rate\": 0.5},\n",
    "    # Fix for \"I1_deep_selu\"\n",
    "    {\"name\": \"I1B_deep_relu_bn\", \"activation\": \"relu\", \"conv_filters\": [64, 128, 256, 512], \"dropout_rate\": 0.4},\n",
    "\n",
    "\n",
    "    # Fix for \"I2_shallow_tanh\"\n",
    "    {\"name\": \"I2B_mid_relu\", \"activation\": \"relu\", \"conv_filters\": [32, 64, 128]},\n",
    "    # Fix for \"A4_selu_k7\"\n",
    "    {\"name\": \"A4B_relu_k7\", \"activation\": \"relu\", \"kernel_size\": 7, \"conv_filters\": [32, 64, 128]},\n",
    "    # Fix for \"A2_tanh_k3\"\n",
    "    {\"name\": \"A2B_relu_k3_deeper\", \"activation\": \"relu\", \"kernel_size\": 3, \"conv_filters\": [32, 64, 128, 256]},\n",
    "    # Fix for \"B1_shallow\"\n",
    "    {\"name\": \"B1B_deep_dense\", \"conv_filters\": [32, 64, 128], \"dense_units\": [256, 128]}\n",
    "]\n",
    "\n",
    "# third batch, take the best from batch 2 and try on 7 classes instead of 13.\n",
    "config_3 = [\n",
    "    {\"name\": \"baseline\"},\n",
    "    {\"name\": \"A3B_relu_k5_improved_7_classes\", \"activation\": \"relu\",\"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256], \"dropout_rate\": 0.5}, \n",
    "    {\"name\": \"B2B_deep_bn_7_classes\", \"conv_filters\": [32, 64, 128, 256, 512], \"activation\": \"relu\", \"dropout_rate\": 0.5, \"batch_norm\": True}, \n",
    "    {\"name\": \"A4B_relu_k7_7_classes\", \"activation\": \"relu\", \"kernel_size\": 7, \"conv_filters\": [32, 64, 128]},\n",
    "]\n",
    "\n",
    "# forth batch, will try the same 7 classes, but without normalising the images\n",
    "# This just made it worse. I have also decided to drop the epochs to 60 since validation is not increasing after that\n",
    "config_4 = [\n",
    "    {\"name\": \"baseline_7_classes_non_normalized\"},\n",
    "    {\"name\": \"A3B_relu_k5_improved_7_classes_non_normalized\", \"activation\": \"relu\",\"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256], \"dropout_rate\": 0.5, \"normalize\": False}, \n",
    "    {\"name\": \"B2B_deep_bn_7_classes_non_normalized\", \"conv_filters\": [32, 64, 128, 256, 512], \"activation\": \"relu\", \"dropout_rate\": 0.5, \"batch_norm\": True,\"normalize\": False}, \n",
    "    {\"name\": \"A4B_relu_k7_7_classes_non_normalized\", \"activation\": \"relu\", \"kernel_size\": 7, \"conv_filters\": [32, 64, 128],\"normalize\": False},\n",
    "]\n",
    "\n",
    "# fifth batch, going back to normalized photos, but will test the same models with matched dense layers and more of them  version of the images\n",
    "# Similar results, not significantlly better \n",
    "config_5 = [\n",
    "    {\"name\": \"baseline_7_classes_dense\"},\n",
    "    {\"name\": \"A3B_relu_k5_improved_7_classes_dense\", \"activation\": \"relu\",\"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\"dense_units\":[256,128], \"dropout_rate\": 0.5}, \n",
    "    {\"name\": \"B2B_deep_bn_7_classes_dense\", \"conv_filters\": [32, 64, 128, 256, 512],\"dense_units\":[512,256,128], \"activation\": \"relu\", \"dropout_rate\": 0.5, \"batch_norm\": True}, \n",
    "    {\"name\": \"A4B_relu_k7_7_classes_dense\", \"activation\": \"relu\", \"kernel_size\": 7, \"conv_filters\": [32, 64, 128],\"dense_units\":[128,64]},\n",
    "]\n",
    "\n",
    "# sixth batch, using previous. models but on grayscale image\n",
    "# yet again, not much change\n",
    "config_6 = [\n",
    "    {\"name\": \"baseline_7_classes_dense\"},\n",
    "    {\"name\": \"A3B_relu_k5_improved_7_classes_dense\", \"activation\": \"relu\",\"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\"dense_units\":[256,128], \"dropout_rate\": 0.5,\"channels\":1}, \n",
    "    {\"name\": \"B2B_deep_bn_7_classes_dense\", \"conv_filters\": [32, 64, 128, 256, 512],\"dense_units\":[512,256,128], \"activation\": \"relu\", \"dropout_rate\": 0.5, \"batch_norm\": True,\"channels\":1}, \n",
    "    {\"name\": \"A4B_relu_k7_7_classes_dense\", \"activation\": \"relu\", \"kernel_size\": 7, \"conv_filters\": [32, 64, 128],\"dense_units\":[128,64],\"channels\":1},\n",
    "]\n",
    "\n",
    "# for batch 7, I will do the training using the previous model on grayscale and 3 channel images\n",
    "# I Messed up and overwrote the grayscale models by the color models. However, the results were extraordinary.\n",
    "# 🔍 B2B_deep_bn_7_classes_dense — Evaluation on Test Set:loss: 1.0621 accuracy: 0.7415\n",
    "# A3B_relu_k5_improved_7_classes_dense — Evaluation on Test Set:loss: 1.0519 accuracy: 0.7343\n",
    "\n",
    "config_7 = [\n",
    "    # 3 channels\n",
    "    {\"name\": \"baseline_7_classes_aug\",\"channels\":3,\"aug_data\":True},\n",
    "    {\"name\": \"A3B_relu_k5_improved_7_classes_dense\", \"activation\": \"relu\",\"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\"dense_units\":[256,128], \"dropout_rate\": 0.5,\"channels\":3,\"aug_data\":True}, \n",
    "    {\"name\": \"B2B_deep_bn_7_classes_dense\", \"conv_filters\": [32, 64, 128, 256, 512],\"dense_units\":[512,256,128], \"activation\": \"relu\", \"dropout_rate\": 0.5, \"batch_norm\": True,\"channels\":3,\"aug_data\":True}, \n",
    "    {\"name\": \"A4B_relu_k7_7_classes_dense\", \"activation\": \"relu\", \"kernel_size\": 7, \"conv_filters\": [32, 64, 128],\"dense_units\":[128,64],\"channels\":3,\"aug_data\":True},\n",
    "]\n",
    "\n",
    "# Batch 8, I'll do the same test but with gray scale to check for differences.\n",
    "# didn't go better, had sligly less accurate models. Gray scale is not good. \n",
    "# Also, due to the size of the augmented data, training takes way way way longer.\n",
    "# So I have decided to only continue with the top 2 models so far, that being the B2B_deep_bn_7_classes_dense and A3B_relu_k5_improved_7_classes_dense\n",
    "\n",
    "config_8 = [\n",
    "    # grayscale channels\n",
    "    {\"name\": \"baseline_7_classes_aug_gray\",\"channels\":1,\"aug_data\":True},\n",
    "    {\"name\": \"A3B_relu_k5_improved_7_classes_dense_aug_gray\", \"activation\": \"relu\",\"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\"dense_units\":[256,128], \"dropout_rate\": 0.5,\"channels\":1,\"aug_data\":True}, \n",
    "    {\"name\": \"B2B_deep_bn_7_classes_dense_aug_gray\", \"conv_filters\": [32, 64, 128, 256, 512],\"dense_units\":[512,256,128], \"activation\": \"relu\", \"dropout_rate\": 0.5, \"batch_norm\": True,\"channels\":1,\"aug_data\":True}, \n",
    "    {\"name\": \"A4B_relu_k7_7_classes_dense_aug_gray\", \"activation\": \"relu\", \"kernel_size\": 7, \"conv_filters\": [32, 64, 128],\"dense_units\":[128,64],\"channels\":1,\"aug_data\":True},\n",
    "]\n",
    "# batch 9, I used the functional model api to make it to allow skip connections,\n",
    "# this should, in theory, make the large CNN perform better.\n",
    "# updated batch_size to 512 for faster training\n",
    "# FINALLY, I broke through the ice I had set in my head as the minimum, that being 80%+ accuracy on the test data set.\n",
    "# That is also where I am doing to stop. \n",
    "# The grand winners for the classification are:\n",
    "#  B2B_deep_bn_7_classes_dense_aug_batch_norm_skip and  A3B_relu_k5_improved_7_classes_dense_aug_skip\n",
    "config_9=[\n",
    "    #skip true , batch norm true, batch norm dense true\n",
    "    {\"name\": \"A3B_relu_k5_improved_7_classes_dense_aug_batch_norm_skip\", \"activation\": \"relu\",\"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\"dense_units\":[256,128],\"batch_norm\": True,\"batch_norm_dense\": True, \"dropout_rate\": 0.5,\"aug_data\":True,\"use_skip\": True},\n",
    "    \n",
    "    {\"name\": \"B2B_deep_bn_7_classes_dense_aug_batch_norm_skip\", \"conv_filters\": [32, 64, 128, 256, 512],\"dense_units\":[512,256,128], \"activation\": \"relu\", \"dropout_rate\": 0.5, \"batch_norm\": True,\"batch_norm_dense\": True,\"aug_data\":True,\"use_skip\":True},\n",
    "    \n",
    "    # skip true, batch norm false, batch norm dense false\n",
    "    {\"name\": \"A3B_relu_k5_improved_7_classes_dense_aug_skip\", \"activation\": \"relu\",\"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\"dense_units\":[256,128], \"dropout_rate\": 0.5,\"aug_data\":True,\"use_skip\": True},\n",
    "    \n",
    "    {\"name\": \"B2B_deep_bn_7_classes_dense_aug_skip\", \"conv_filters\": [32, 64, 128, 256, 512],\"dense_units\":[512,256,128], \"activation\": \"relu\", \"dropout_rate\": 0.5,\"aug_data\":True,\"use_skip\":True},\n",
    "]\n",
    "\n",
    "\n",
    "# Regression time\n",
    "\n",
    "# batch one 1, I'll just train the best model I found so far and go from there\n",
    "# so bad, so many mistakes i made, so many things i forgot. It just failed miserably, MSE is massive.\n",
    "# Will train all the previous models and see where to go from there\n",
    "# Who would've thought, most are not just awful, but outright sad. Only one got a decent results and that is\n",
    "\n",
    "config_10=[\n",
    "    {\"name\": \"baseline\"},\n",
    "    {\"name\": \"baseline_non_normalized\", \"normalize\": False},\n",
    "    {\"name\": \"baseline_dense\"},\n",
    "    {\"name\": \"baseline_aug\", \"aug_data\": True},\n",
    "    {\"name\": \"baseline_aug_gray\", \"channels\": 1, \"aug_data\": True},\n",
    "\n",
    "    {\"name\": \"A1_relu_k3\"},\n",
    "    {\"name\": \"A3_relu_k5\", \"kernel_size\": 5},\n",
    "\n",
    "    {\"name\": \"B2_deep\", \"conv_filters\": [32, 64, 128, 256, 512]},\n",
    "\n",
    "    {\"name\": \"J1_dense_512\", \"dense_units\": [512]},\n",
    "    {\"name\": \"J2_dense_256_128\", \"dense_units\": [256, 128]},\n",
    "    {\"name\": \"E1_dense1\"},\n",
    "    {\"name\": \"E2_dense3\", \"dense_units\": [256, 128, 64]},\n",
    "\n",
    "    {\"name\": \"F1_gray\", \"channels\": 1},\n",
    "    {\"name\": \"F2_gray_k5\", \"channels\": 1, \"kernel_size\": 5},\n",
    "    {\"name\": \"F3_gray_deep\", \"channels\": 1, \"conv_filters\": [32, 64, 128, 256]},\n",
    "    {\"name\": \"F4_gray_dense2\", \"channels\": 1, \"dense_units\": [256, 128]},\n",
    "\n",
    "    {\"name\": \"H1_dropout_0.3\", \"dropout_rate\": 0.3},\n",
    "    {\"name\": \"H2_dropout_0.7\", \"dropout_rate\": 0.7},\n",
    "\n",
    "    {\"name\": \"B3_batch_128\", \"batch_size\": 128},\n",
    "    {\"name\": \"B4_batch_64\", \"batch_size\": 64},\n",
    "\n",
    "    {\"name\": \"E1_epochs_60\", \"epochs\": 60},\n",
    "    {\"name\": \"E2_epochs_180\", \"epochs\": 180},\n",
    "    {\"name\": \"E3_epochs_240\", \"epochs\": 240},\n",
    "    {\"name\": \"E4_epochs_300\", \"epochs\": 300},\n",
    "\n",
    "    {\"name\": \"K1_k7_deep\", \"kernel_size\": 7, \"conv_filters\": [64, 128, 256]},\n",
    "\n",
    "    {\"name\": \"B2B_deep_bn\", \"conv_filters\": [32, 64, 128, 256, 512], \"batch_norm\": True},\n",
    "    {\"name\": \"K1B_k7_deep_bn\", \"kernel_size\": 7, \"conv_filters\": [64, 128, 256, 512],\n",
    "     \"dropout_rate\": 0.4, \"batch_norm\": True},\n",
    "    {\"name\": \"E4B_epochs_300\", \"epochs\": 300, \"lr_schedule\": \"reduce_on_plateau\"},\n",
    "    {\"name\": \"J2B_dense_256_128\", \"dense_units\": [256, 128], \"batch_norm_dense\": True},\n",
    "    {\"name\": \"A3B_relu_k5_improved\", \"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256]},\n",
    "    {\"name\": \"I1B_deep_relu_bn\", \"conv_filters\": [64, 128, 256, 512], \"dropout_rate\": 0.4},\n",
    "    {\"name\": \"I2B_mid_relu\"},\n",
    "    {\"name\": \"A4B_relu_k7\", \"kernel_size\": 7},\n",
    "    {\"name\": \"A2B_relu_k3_deeper\", \"conv_filters\": [32, 64, 128, 256]},\n",
    "    {\"name\": \"B1B_deep_dense\", \"dense_units\": [256, 128]},\n",
    "\n",
    "    {\"name\": \"A3B_relu_k5_improved_reg\", \"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256]},\n",
    "    {\"name\": \"B2B_deep_bn_reg\", \"conv_filters\": [32, 64, 128, 256, 512], \"batch_norm\": True},\n",
    "    {\"name\": \"A4B_relu_k7_reg\", \"kernel_size\": 7},\n",
    "    {\"name\": \"A3B_relu_k5_improved_reg_non_norm\", \"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\n",
    "     \"normalize\": False},\n",
    "    {\"name\": \"B2B_deep_bn_reg_non_norm\", \"conv_filters\": [32, 64, 128, 256, 512],\n",
    "     \"batch_norm\": True, \"normalize\": False},\n",
    "    {\"name\": \"A4B_relu_k7_reg_non_norm\", \"kernel_size\": 7, \"normalize\": False},\n",
    "    {\"name\": \"A3B_relu_k5_improved_reg_dense\", \"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\n",
    "     \"dense_units\": [256, 128]},\n",
    "    {\"name\": \"B2B_deep_bn_reg_dense\", \"conv_filters\": [32, 64, 128, 256, 512],\n",
    "     \"dense_units\": [512, 256, 128], \"batch_norm\": True},\n",
    "    {\"name\": \"A4B_relu_k7_reg_dense\", \"kernel_size\": 7, \"dense_units\": [128, 64]},\n",
    "    {\"name\": \"A3B_relu_k5_improved_reg_dense_gray\", \"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\n",
    "     \"dense_units\": [256, 128], \"channels\": 1},\n",
    "    {\"name\": \"B2B_deep_bn_reg_dense_gray\", \"conv_filters\": [32, 64, 128, 256, 512],\n",
    "     \"dense_units\": [512, 256, 128], \"batch_norm\": True, \"channels\": 1},\n",
    "    {\"name\": \"A4B_relu_k7_reg_dense_gray\", \"kernel_size\": 7, \"channels\": 1},\n",
    "    {\"name\": \"A3B_relu_k5_improved_reg_aug\", \"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\n",
    "     \"dense_units\": [256, 128], \"aug_data\": True},\n",
    "    {\"name\": \"B2B_deep_bn_reg_aug\", \"conv_filters\": [32, 64, 128, 256, 512],\n",
    "     \"dense_units\": [512, 256, 128], \"batch_norm\": True, \"aug_data\": True},\n",
    "    {\"name\": \"A4B_relu_k7_reg_aug\", \"kernel_size\": 7, \"aug_data\": True},\n",
    "    {\"name\": \"A3B_relu_k5_improved_reg_aug_gray\", \"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\n",
    "     \"dense_units\": [256, 128], \"channels\": 1, \"aug_data\": True},\n",
    "    {\"name\": \"B2B_deep_bn_reg_aug_gray\", \"conv_filters\": [32, 64, 128, 256, 512],\n",
    "     \"dense_units\": [512, 256, 128], \"batch_norm\": True, \"channels\": 1, \"aug_data\": True},\n",
    "    {\"name\": \"A4B_relu_k7_reg_aug_gray\", \"kernel_size\": 7, \"channels\": 1, \"aug_data\": True},\n",
    "    {\"name\": \"A3B_relu_k5_improved_reg_aug_bn_skip\", \"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\n",
    "     \"dense_units\": [256, 128], \"batch_norm\": True, \"batch_norm_dense\": True,\n",
    "     \"aug_data\": True, \"use_skip\": True},\n",
    "    {\"name\": \"B2B_deep_bn_reg_aug_bn_skip\", \"conv_filters\": [32, 64, 128, 256, 512],\n",
    "     \"dense_units\": [512, 256, 128], \"batch_norm\": True, \"batch_norm_dense\": True,\n",
    "     \"aug_data\": True, \"use_skip\": True},\n",
    "    {\"name\": \"A3B_relu_k5_improved_reg_aug_skip\", \"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\n",
    "     \"dense_units\": [256, 128], \"aug_data\": True, \"use_skip\": True},\n",
    "    {\"name\": \"B2B_deep_bn_reg_aug_skip\", \"conv_filters\": [32, 64, 128, 256, 512],\n",
    "     \"dense_units\": [512, 256, 128], \"aug_data\": True, \"use_skip\": True},\n",
    "]\n",
    "\n",
    "# I have no idea why but B2B_deep_bn_reg_dense_gray got an outlier of a result, 51 MSE. I will check this one in depth with more epochs and see what's happening\n",
    "# Ok so, i found out somehting interesting, my validation loss goes very high in the first 30 - ish epochs and then \n",
    "# comes down to a decent value. The early stopping was causing the models to be pretty much random,\n",
    "# \n",
    "config_11 = [\n",
    "    {\"name\": \"B2B_deep_bn_reg_dense_gray\", \"conv_filters\": [32, 64, 128, 256, 512],\"dense_units\": [512, 256, 128], \"batch_norm\": True, \"channels\": 1},\n",
    "    {\"name\": \"B2B_deep_bn\",\"conv_filters\": [32, 64, 128, 256, 512],\"batch_norm\": True,}\n",
    "\n",
    "]\n",
    "# Trained the best again with delayed early stopping and 120 epochs.\n",
    "config_12 = [\n",
    "    {\"name\": \"B2B_deep_bn_reg_dense_gray\", \"conv_filters\": [32, 64, 128, 256, 512],\"dense_units\": [512, 256, 128], \"batch_norm\": True, \"channels\": 1},\n",
    "    {\"name\": \"B2B_deep_bn_reg\", \"conv_filters\": [32, 64, 128, 256, 512], \"batch_norm\": True},\n",
    "    \n",
    "    {\"name\": \"A3B_relu_k5_reg_dense_aug_bn_skip\", \"activation\": \"relu\",\"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\"dense_units\":[256,128],\"batch_norm\": True,\"batch_norm_dense\": True, \"dropout_rate\": 0.5,\"aug_data\":True,\"use_skip\": True},\n",
    "    \n",
    "    {\"name\": \"B2B_deep_bn_reg_dense_aug_bn_skip\", \"conv_filters\": [32, 64, 128, 256, 512],\"dense_units\":[512,256,128], \"activation\": \"relu\", \"dropout_rate\": 0.5, \"batch_norm\": True,\"batch_norm_dense\": True,\"aug_data\":True,\"use_skip\":True},\n",
    "    \n",
    "    {\"name\": \"A3B_relu_k5_reg_dense_aug_skip\", \"activation\": \"relu\",\"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\"dense_units\":[256,128], \"dropout_rate\": 0.5,\"aug_data\":True,\"use_skip\": True},\n",
    "    \n",
    "    {\"name\": \"B2B_deep_reg_dense_aug_skip\", \"conv_filters\": [32, 64, 128, 256, 512],\"dense_units\":[512,256,128], \"activation\": \"relu\", \"dropout_rate\": 0.5,\"aug_data\":True,\"use_skip\":True},\n",
    "]\n",
    "\n",
    "# not half bad. some decent results, I would say, swtiched to mae for validation because it makes a bit more sense to me.\n",
    "# How far off are we from the real age? That's pretty much it. And I got a 7.17 and a 7.99. Not good, but not bad\n",
    "# definitely way better than some other ones.\n",
    "config_13 = [\n",
    "{\"name\": \"B2B_deep_bn_reg_aug_bn_skip\", \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"batch_norm_dense\": True, \"aug_data\": True, \"use_skip\": True},\n",
    "{\"name\": \"B2B_deep_bn_reg_aug\", \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"aug_data\": True},\n",
    "{\"name\": \"B2B_deep_bn_reg_aug_skip\", \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"aug_data\": True, \"use_skip\": True},\n",
    "{\"name\": \"A3B_relu_k5_improved_reg_aug\", \"kernel_size\": 5, \"conv_filters\": [32,64,128,256], \"dense_units\": [256,128], \"aug_data\": True},\n",
    "{\"name\": \"B2B_deep_bn_reg_aug_gray\", \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"channels\": 1, \"aug_data\": True},\n",
    "\n",
    "# added l2 reglr\n",
    "{\"name\": \"B2B_deep_bn_reg_dense_gray\", \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"channels\": 1,\"l2_reg\":1e-4},\n",
    "{\"name\": \"B2B_deep_bn_reg\", \"conv_filters\": [32,64,128,256,512], \"batch_norm\": True,\"l2_reg\":1e-4},\n",
    "{\"name\": \"B2B_deep_bn\", \"conv_filters\": [32,64,128,256,512], \"batch_norm\": True, \"l2_reg\":1e-4},\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "# I'll take the top three from the last training and just train them for longer\n",
    "\n",
    "# B2B_deep_bn_reg_aug\t103.85\t7.17\t\n",
    "# B2B_deep_bn_reg_aug_gray\t136.48\t7.99\n",
    "# B2B_deep_bn_reg_dense_gray\t232.58\t10.67\t\n",
    "\n",
    "\n",
    "# Marginally better results  on B2B_deep_bn_reg_aug_gray    mse: 118.6801 mae: 7.4108\n",
    "# same for B2B_deep_bn_reg_dense_gray mse: 201.5796 mae: 9.9408\n",
    "\n",
    "\n",
    "config_14 = [\n",
    "{\"name\": \"B2B_deep_bn_reg_aug\",\"epochs\":500, \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"aug_data\": True},\n",
    "{\"name\": \"B2B_deep_bn_reg_aug_gray\",\"epochs\":500, \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"channels\": 1, \"aug_data\": True},\n",
    "{\"name\": \"B2B_deep_bn_reg_dense_gray\",\"epochs\":500, \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"channels\": 1,\"l2_reg\":1e-4},\n",
    "\n",
    "# for funsies:\n",
    "{\"name\": \"B2B_deep_bn_reg_aug\",\"epochs\":500,\"activation\":\"linear\", \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"aug_data\": True}\n",
    "]\n",
    "# one last try, adding skip connections and l2 to the best model\n",
    "# CNN_tuned_small_4block_bn_dropout_gap mse: 316.8465 mae: 13.1326\n",
    "# B2B_deep_bn_reg_aug_skip_l2 mse: 152.3895 mae: 8.9242\n",
    "config_15 = [\n",
    "{\"name\": \"CNN_tuned_small_4block_bn_dropout_gap\", \"output_activation\": \"relu\", \"conv_filters\": [32, 64, 128, 256], \"dense_units\": [128], \"batch_norm\": True, \"dropout_rate\": 0.5, \"aug_data\": True, \"l2_reg\": 1e-4, \"batch_size\": 1024},\n",
    "{\"name\": \"B2B_deep_bn_reg_aug_skip_l2\",\"output_activation\":\"linear\",\"batch_size\": 1024,\"epochs\":500, \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"aug_data\": True,\"l2_reg\":1e-4,\"use_skip\":True},\n",
    "]\n",
    "\n",
    "\n",
    "config_16 = [\n",
    "#     loss: 387.7751 mae: 14.8765\n",
    " \n",
    "{\"name\": \"CNN_tuned_small_4block_bn_dropout_gap\",\"epochs\":1000, \"output_activation\": \"relu\", \"conv_filters\": [32, 64, 128, 256], \"dense_units\": [128], \"batch_norm\": True, \"dropout_rate\": 0.5, \"aug_data\": False, \"l2_reg\": 1e-4, \"batch_size\": 256},\n",
    "\n",
    "]\n",
    "# Absolutely insane performance pulled off here. 5.5 MAE on test set\n",
    "#  Will let it train for even longer by disabling the early stopper maybe\n",
    "# I believe it can be even better \n",
    "config_17=[\n",
    "# B2B_deep_bn_reg_aug  mse: 63.5034 mae: 5.5665\n",
    "{\"name\": \"B2B_deep_bn_reg_aug\",\"epochs\":500, \"l2_reg\": 1e-4,\"batch_size\":256,\"batch_norm_dense\":True, \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"aug_data\": True},\n",
    "{\"name\": \"B2B_deep_bn_reg_aug_linear\", \"activation\": \"linear\",\"epochs\":500, \"l2_reg\": 1e-4,\"batch_size\":256,\"batch_norm_dense\":True, \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"aug_data\": True},\n",
    "\n",
    "]\n",
    "\n",
    "# now with these two nice models, I'll try again them for the classification\n",
    "# B2B_deep_bn_reg_aug_classification_7_class — Evaluation on Test Set: loss: 0.8003 accuracy: 0.6729\n",
    "\n",
    "# B2B_deep_bn_reg_aug_classification_13_class — Evaluation on Test Set: loss: 0.7616 accuracy: 0.6855\n",
    "\n",
    "confi_18=[\n",
    "{\"name\": \"B2B_deep_bn_reg_aug_classification_7_class\",\"task\":\"classification\",\"num_classes\":7,\"epochs\":500, \"l2_reg\": 1e-4,\"batch_size\":256,\"batch_norm_dense\":True, \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"aug_data\": True},\n",
    "{\"name\": \"B2B_deep_bn_reg_aug_classification_13_class\",\"task\":\"classification\",\"num_classes\":13,\"epochs\":500, \"l2_reg\": 1e-4,\"batch_size\":256,\"batch_norm_dense\":True, \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"aug_data\": True},\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:00:09.546844Z",
     "start_time": "2025-04-08T15:00:09.319452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_count = 19\n",
    "\n",
    "# To try to train these again to try to get the same accuracy again.\n",
    "#   {\"name\": \"A3B_relu_k5_improved_7_classes_dense_aug_batch_norm_skip\", \"activation\": \"relu\",\"kernel_size\": 5, \"conv_filters\": [32, 64, 128, 256],\"dense_units\":[256,128],\"batch_norm\": True,\"batch_norm_dense\": True, \"dropout_rate\": 0.5,\"aug_data\":True,\"use_skip\": True}, \n",
    "# {\"name\": \"B2B_deep_bn_7_classes_dense_aug_batch_norm_skip\", \"conv_filters\": [32, 64, 128, 256, 512],\"dense_units\":[512,256,128], \"activation\": \"relu\", \"dropout_rate\": 0.5, \"batch_norm\": True,\"batch_norm_dense\": True,\"aug_data\":True,\"use_skip\":True},\n",
    "    \n",
    "configs = [\n",
    "    {\"name\": \"B2B_deep_bn_reg_aug_autoencoder\",\"epochs\":500, \"l2_reg\": 1e-4,\"batch_size\":256,\"batch_norm_dense\":True, \"conv_filters\": [32,64,128,256,512], \"dense_units\": [512,256,128], \"batch_norm\": True, \"aug_data\": True,\"task\":\"regression\",\"resize\":(192,192)},\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "default_args = {\n",
    "    \"batch_size\": 512,\n",
    "    \"epochs\": 200,\n",
    "    \"channels\": 3,\n",
    "    \"dropout_rate\": 0.5,\n",
    "    \"task\": \"regression\",\n",
    "    \"num_classes\": 7,\n",
    "    \"conv_filters\": [32, 64, 128],\n",
    "    \"kernel_size\": 3,\n",
    "    \"activation\": \"relu\",\n",
    "    \"dense_units\": [128],\n",
    "    \"output_activation\": \"softmax\",\n",
    "    \"batch_norm\" : False,\n",
    "    \"batch_norm_dense\": False,\n",
    "    \"normalize\" : True,\n",
    "    \"aug_data\": False,\n",
    "    \"use_skip\": False,\n",
    "    \"l2_reg\":0\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "ratio=1\n",
    "# Build all models and store in DataFrame\n",
    "model_list = []\n",
    "for cfg in configs:\n",
    "    cfg_full = {**default_args, **cfg}\n",
    "    cfg_full[\"loss\"]='categorical_crossentropy' if cfg_full[\"task\"] ==\"classification\" else \"mse\"\n",
    "    cfg_full[\"metrics\"]=['accuracy'] if cfg_full[\"task\"] ==\"classification\" else [\"mse\",\"mae\"]\n",
    "    \n",
    "    \n",
    "    dict_for_data= aug_data if cfg_full[\"aug_data\"] else data\n",
    "    label_kind = \"labels\" if cfg_full[\"task\"] ==\"classification\" else \"labels_regr\"\n",
    "    train_dataset = load_images_from_paths(dict_for_data[\"train\"][\"filenames\"],\n",
    "                                           dict_for_data[\"train\"][label_kind], \n",
    "                                           channels=cfg_full[\"channels\"],\n",
    "                                           ratio=ratio,\n",
    "                                           batch_size=cfg_full['batch_size'],\n",
    "                                           class_count=cfg_full['num_classes'],\n",
    "                                           task=cfg_full['task'])\n",
    "    \n",
    "    val_dataset = load_images_from_paths(data[\"val\"][\"filenames\"], data[\"val\"][label_kind],\n",
    "                                         channels=cfg_full[\"channels\"],\n",
    "                                         ratio=ratio,\n",
    "                                         batch_size=cfg_full['batch_size'],\n",
    "                                         class_count=cfg_full['num_classes'],\n",
    "                                         task=cfg_full['task'])\n",
    "\n",
    "    test_dataset = load_images_from_paths(data[\"test\"][\"filenames\"], data[\"test\"][label_kind],\n",
    "                                         channels=cfg_full[\"channels\"],\n",
    "                                         ratio=ratio,\n",
    "                                         batch_size=cfg_full['batch_size'],\n",
    "                                         class_count=cfg_full['num_classes'],\n",
    "                                         task=cfg_full['task'])\n",
    "    \n",
    "    # if skip, make it functional \n",
    "    model = build_cnn_model(\n",
    "            channels=cfg_full[\"channels\"],\n",
    "            dropout_rate=cfg_full[\"dropout_rate\"],\n",
    "            task=cfg_full[\"task\"],\n",
    "            num_classes=cfg_full[\"num_classes\"],\n",
    "            conv_filters=cfg_full[\"conv_filters\"],\n",
    "            kernel_size=cfg_full[\"kernel_size\"],\n",
    "            activation=cfg_full[\"activation\"],\n",
    "            dense_units=cfg_full[\"dense_units\"],\n",
    "            output_activation=cfg_full[\"output_activation\"],\n",
    "            batch_norm=cfg_full[\"batch_norm\"],\n",
    "            batch_norm_dense=cfg_full[\"batch_norm_dense\"],\n",
    "            use_skip=cfg_full[\"use_skip\"],\n",
    "    )\n",
    "\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.00001)\n",
    "    model.compile(loss=cfg_full[\"loss\"], optimizer=optimizer, metrics=cfg_full[\"metrics\"])\n",
    "    cfg_full[\"model\"] = model\n",
    "    cfg_full[\"train_data\"]=train_dataset\n",
    "    cfg_full[\"val_data\"]=val_dataset\n",
    "    cfg_full[\"test_data\"]=test_dataset\n",
    "    \n",
    "    model_list.append(cfg_full)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T15:00:11.145332Z",
     "start_time": "2025-04-08T15:00:11.132719Z"
    }
   },
   "cell_type": "code",
   "source": "model_list[0]['model'].summary()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_2\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m190\u001B[0m, \u001B[38;5;34m190\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │           \u001B[38;5;34m896\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m190\u001B[0m, \u001B[38;5;34m190\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_10            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m95\u001B[0m, \u001B[38;5;34m95\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mAveragePooling2D\u001B[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m93\u001B[0m, \u001B[38;5;34m93\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │        \u001B[38;5;34m18,496\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m93\u001B[0m, \u001B[38;5;34m93\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │           \u001B[38;5;34m256\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_11            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m46\u001B[0m, \u001B[38;5;34m46\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mAveragePooling2D\u001B[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m44\u001B[0m, \u001B[38;5;34m44\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │        \u001B[38;5;34m73,856\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m44\u001B[0m, \u001B[38;5;34m44\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │           \u001B[38;5;34m512\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_12            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m22\u001B[0m, \u001B[38;5;34m22\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mAveragePooling2D\u001B[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │       \u001B[38;5;34m295,168\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │         \u001B[38;5;34m1,024\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_13            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mAveragePooling2D\u001B[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │     \u001B[38;5;34m1,180,160\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │         \u001B[38;5;34m2,048\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_14            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mAveragePooling2D\u001B[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)            │       \u001B[38;5;34m262,656\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)            │         \u001B[38;5;34m2,048\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │       \u001B[38;5;34m131,328\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │         \u001B[38;5;34m1,024\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │        \u001B[38;5;34m32,896\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │           \u001B[38;5;34m512\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m129\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">190</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">190</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">190</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">190</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_10            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_11            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_12            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_13            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_14            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m2,003,137\u001B[0m (7.64 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,003,137</span> (7.64 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,999,361\u001B[0m (7.63 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,999,361</span> (7.63 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m3,776\u001B[0m (14.75 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,776</span> (14.75 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for config in model_list:\n",
    "    print(f\"\\nModel: {config['name']}\")\n",
    "    \n",
    "    # Create iterators for the datasets\n",
    "    train_iter = iter(config[\"train_data\"])\n",
    "    val_iter = iter(config[\"val_data\"])\n",
    "    test_iter = iter(config[\"test_data\"])\n",
    "    \n",
    "    # Print header\n",
    "    header = \"{:<5}{:<25}{:<25}{:<25}\".format(\"Idx\", \"Train Label\", \"Val Label\", \"Test Label\")\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    \n",
    "    # Iterate for the first 10 batches\n",
    "    for i in range(2):\n",
    "        train_sample = next(train_iter, None)\n",
    "        val_sample = next(val_iter, None)\n",
    "        test_sample = next(test_iter, None)\n",
    "        \n",
    "        # Extract labels; assume each sample is (data, label)\n",
    "        train_label = train_sample[1] if train_sample is not None else \"None\"\n",
    "        val_label = val_sample[1] if val_sample is not None else \"None\"\n",
    "        test_label = test_sample[1] if test_sample is not None else \"None\"\n",
    "        \n",
    "        # Convert tensors to lists for readable output (if needed)\n",
    "        if hasattr(train_label, \"numpy\"):\n",
    "            train_label = train_label.numpy().tolist()\n",
    "        if hasattr(val_label, \"numpy\"):\n",
    "            val_label = val_label.numpy().tolist()\n",
    "        if hasattr(test_label, \"numpy\"):\n",
    "            test_label = test_label.numpy().tolist()\n",
    "        \n",
    "        # Print the formatted row\n",
    "        row = \"{:<5}{:<25}{:<25}{:<25}\".format(i, str(train_label), str(val_label), str(test_label))\n",
    "        print(row)\n",
    "    \n",
    "    print(\"-\" * len(header))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model_list"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Fitting"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "os.makedirs(f\"regression_saved_models_config_{config_count}\", exist_ok=True)\n",
    "os.makedirs(f\"classification_saved_models_config_{config_count}\", exist_ok=True)\n",
    "\n",
    "\n",
    "for entry in model_list:\n",
    "    model_name = entry[\"name\"]\n",
    "    \n",
    "    # Setup model checkpoint callback\n",
    "    checkpoint_path = f\"{entry['task']}_saved_models_config_{config_count}/{model_name}_best_model.keras\"\n",
    "    mse_checkpoint = ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy' if entry[\"task\"]=='classification' else 'val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=0\n",
    "    )\n",
    "    entry['best_model_path'] = checkpoint_path\n",
    "\n",
    "    callbacks = [mse_checkpoint]\n",
    "\n",
    "    if entry[\"task\"]!='classification':\n",
    "        mae_checkpoint = ModelCheckpoint(\n",
    "            filepath=checkpoint_path,\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            verbose=0\n",
    "        )\n",
    "        callbacks.append(mae_checkpoint)\n",
    "\n",
    "    # useless or I'm dumb and don't know how to use it properly\n",
    "    if \"lr_schedule\" in entry:\n",
    "        if entry[\"lr_schedule\"] == \"reduce_on_plateau\":\n",
    "            lr_callback = ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                verbose=1\n",
    "            )\n",
    "            callbacks.append(lr_callback)\n",
    "\n",
    "    early_stop_loss = DelayedEarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        restore_best_weights=False,\n",
    "        delay=60  # begin checks after 60 epochs\n",
    "    )\n",
    "    \n",
    "    if entry[\"task\"]=='classification':\n",
    "        early_stop_acc = DelayedEarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=7,\n",
    "            verbose=0,\n",
    "            restore_best_weights=True,\n",
    "            delay=60\n",
    "        )\n",
    "        callbacks.append(early_stop_acc)\n",
    "\n",
    "    callbacks.append(early_stop_loss)\n",
    "    callbacks.append(LiveLossPlot(model_name=model_name))\n",
    "\n",
    "    # Train model\n",
    "    history = entry['model'].fit(\n",
    "        entry['train_data'],\n",
    "        validation_data=entry['val_data'],\n",
    "        epochs=entry['epochs'],\n",
    "        batch_size=entry['batch_size'],\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # Save training history in entry\n",
    "    entry['history'] = history.history\n",
    "    entry['best_model_path'] = checkpoint_path\n",
    "    df_model_summary = pd.DataFrame([\n",
    "    {k: v for k, v in entry.items() if k not in ['model', 'train_data', 'val_data','test_data']} for entry in model_list])\n",
    "    df_model_summary.to_csv(f\"regr_model_summary_config_{config_count}.csv\", index=False)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Checking Model Performance"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:20:35.146556Z",
     "start_time": "2025-04-07T14:20:35.060936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Create subplots: one row per model, two columns (loss and accuracy)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(model_list), ncols=2, figsize=(15, 5 * len(model_list)))\n",
    "\n",
    "# Ensure axes is always 2D\n",
    "if len(model_list) == 1:\n",
    "    axes = np.array([axes])\n",
    "\n",
    "# Loop through each trained model entry\n",
    "for i, entry in enumerate(model_list):\n",
    "    try:\n",
    "        model_name = entry[\"name\"]\n",
    "        history = entry[\"history\"]\n",
    "        epochs = list(range(1, len(history[\"loss\"]) + 1))\n",
    "\n",
    "        # Loss Plot\n",
    "        ax_loss = axes[i, 0]\n",
    "        ax_loss.plot(epochs, history[\"loss\"], label='Train Loss', marker='o')\n",
    "        ax_loss.plot(epochs, history[\"val_loss\"], label='Val Loss', marker='o')\n",
    "        ax_loss.set_title(f\"{model_name} - Loss\")\n",
    "        ax_loss.set_xlabel(\"Epoch\")\n",
    "        ax_loss.set_ylabel(\"Loss\")\n",
    "        ax_loss.legend()\n",
    "\n",
    "        # Accuracy Plot\n",
    "        ax_acc = axes[i, 1]\n",
    "        ax_acc.plot(epochs, history[\"accuracy\"], label='Train Accuracy', marker='o')\n",
    "        ax_acc.plot(epochs, history[\"val_accuracy\"], label='Val Accuracy', marker='o')\n",
    "        ax_acc.set_title(f\"{model_name} - Accuracy\")\n",
    "        ax_acc.set_xlabel(\"Epoch\")\n",
    "        ax_acc.set_ylabel(\"Accuracy\")\n",
    "        ax_acc.legend()\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Create subplots: one row per model, two columns (loss and accuracy)\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m fig, axes = plt.subplots(nrows=\u001B[38;5;28mlen\u001B[39m(\u001B[43mmodel_list\u001B[49m), ncols=\u001B[32m2\u001B[39m, figsize=(\u001B[32m15\u001B[39m, \u001B[32m5\u001B[39m * \u001B[38;5;28mlen\u001B[39m(model_list)))\n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m# Ensure axes is always 2D\u001B[39;00m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(model_list) == \u001B[32m1\u001B[39m:\n",
      "\u001B[31mNameError\u001B[39m: name 'model_list' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_preds_and_labels(model, dataset):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for batch in dataset:\n",
    "        images, labels = batch\n",
    "        probs = model.predict(images, verbose=0)\n",
    "        y_pred.extend(np.argmax(probs, axis=-1))\n",
    "        y_true.extend(labels.numpy())\n",
    "    return np.array(y_pred), np.array(y_true)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_list",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:21:36.403649Z",
     "start_time": "2025-04-07T14:21:36.313260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "ratio=1\n",
    "model_list_loaded=pd.read_csv(f\"regression_model_summary_config_16.csv\")\n",
    "model_list = []\n",
    "for _, row in model_list_loaded.iterrows():\n",
    "    if pd.notna(row[\"history\"]):\n",
    "        history_dict = ast.literal_eval(row[\"history\"])\n",
    "        print(row[\"aug_data\"])\n",
    "        model_list.append({\n",
    "            \"name\": row[\"name\"],\n",
    "            \"history\": history_dict,\n",
    "            \"aug_data\": row[\"aug_data\"],\n",
    "            \"channels\": row[\"channels\"],\n",
    "            \"batch_size\": row[\"batch_size\"],\n",
    "            \"num_classes\": row[\"num_classes\"],\n",
    "            \"normalize\": row[\"normalize\"],\n",
    "            \"task\": row[\"task\"]\n",
    "        })\n"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'regression_model_summary_config_16.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mast\u001B[39;00m\n\u001B[32m      2\u001B[39m ratio=\u001B[32m1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m model_list_loaded=\u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mregression_model_summary_config_16.csv\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m model_list = []\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _, row \u001B[38;5;129;01min\u001B[39;00m model_list_loaded.iterrows():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1878\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m   1879\u001B[39m         mode += \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1880\u001B[39m \u001B[38;5;28mself\u001B[39m.handles = \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1881\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1882\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1883\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1884\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcompression\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1885\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmemory_map\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1886\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1887\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding_errors\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstrict\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1888\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstorage_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1889\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1890\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1891\u001B[39m f = \u001B[38;5;28mself\u001B[39m.handles.handle\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/pandas/io/common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'regression_model_summary_config_16.csv'"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Create subplots: one row per model, two columns (loss and accuracy)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(model_list), ncols=2, figsize=(15, 5 * len(model_list)))\n",
    "\n",
    "# Ensure axes is always 2D\n",
    "if len(model_list) == 1:\n",
    "    axes = np.array([axes])\n",
    "\n",
    "# Loop through each trained model entry\n",
    "for i, entry in enumerate(model_list):\n",
    "    try:\n",
    "        model_name = entry[\"name\"]\n",
    "        history = entry[\"history\"]\n",
    "        epochs = list(range(1, len(history[\"loss\"]) + 1))\n",
    "\n",
    "        # Loss Plot\n",
    "        ax_loss = axes[i, 0]\n",
    "        ax_loss.plot(epochs, history[\"loss\"], label='Train Loss', marker='o')\n",
    "        ax_loss.plot(epochs, history[\"val_loss\"], label='Val Loss', marker='o')\n",
    "        ax_loss.set_title(f\"{model_name} - Loss\")\n",
    "        ax_loss.set_xlabel(\"Epoch\")\n",
    "        ax_loss.set_ylabel(\"Loss\")\n",
    "        ax_loss.legend()\n",
    "\n",
    "        # Accuracy Plot\n",
    "        ax_acc = axes[i, 1]\n",
    "        ax_acc.plot(epochs, history[\"accuracy\"], label='Train Accuracy', marker='o')\n",
    "        ax_acc.plot(epochs, history[\"val_accuracy\"], label='Val Accuracy', marker='o')\n",
    "        ax_acc.set_title(f\"{model_name} - Accuracy\")\n",
    "        ax_acc.set_xlabel(\"Epoch\")\n",
    "        ax_acc.set_ylabel(\"Accuracy\")\n",
    "        ax_acc.legend()\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "for entry in model_list:\n",
    "    # try:\n",
    "        # print(entry[\"aug_data\"])\n",
    "        dict_for_data= aug_data if entry[\"aug_data\"] else data\n",
    "        label_kind = \"labels\" if entry[\"task\"] ==\"classification\" else \"labels_regr\"\n",
    "\n",
    "\n",
    "        test_dataset = load_images_from_paths(data[\"test\"][\"filenames\"], data[\"test\"][label_kind],\n",
    "                                         channels=entry[\"channels\"],\n",
    "                                         ratio=ratio,\n",
    "                                         batch_size=entry['batch_size'],\n",
    "                                         class_count=entry['num_classes'],\n",
    "                                         normalize=entry['normalize'],\n",
    "                                         task=entry[\"task\"])\n",
    "\n",
    "\n",
    "        entry[\"test_data\"]=test_dataset\n",
    "\n",
    "    # except Exception:\n",
    "        # print(\"bad\")\n",
    "        # continue\n",
    "    \n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%whos "
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "config_count=9\n",
    "# Loop through each trained model entry\n",
    "for i, entry in enumerate(model_list):\n",
    "    \n",
    "        model_name = entry[\"name\"]\n",
    "        best_model_path = f\"saved_models_config_{config_count}/{model_name}_best_model.keras\"\n",
    "        \n",
    "        test_dataset = entry['test_data']\n",
    "        # Load the best saved model\n",
    "        \n",
    "        model = load_model(best_model_path)\n",
    "        \n",
    "\n",
    "        # Evaluate on test set\n",
    "        model_score = model.evaluate(test_dataset, verbose=1)\n",
    "        model_labels = model.metrics_names\n",
    "\n",
    "        print(f\"🔍 {model_name} — Evaluation on Test Set:\")\n",
    "        for label, score in zip(model_labels, model_score):\n",
    "            print(f\"   {label}: {round(score, 4)}\")\n",
    "        print(\"-\" * 40)\n",
    "        y_pred = model.predict(test_dataset)\n",
    "        y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "\n",
    "        # Print predicted vs true values\n",
    "        print(\"📋 Predictions vs Ground Truth:\")\n",
    "        # for pred, true in zip(y_pred.flatten(), y_true.flatten()):\n",
    "            # print(f\"   Predicted: {round(pred, 2)} — Actual: {int(true)}\")\n",
    "        pred_classes = np.argmax(y_pred, axis=1)\n",
    "        true_classes = np.argmax(y_true, axis=1)\n",
    "\n",
    "        for pred, true in zip(pred_classes, true_classes):\n",
    "            print(f\"   Predicted: {pred} — Actual: {true}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plotting Confusion Matrix"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Defining a function to plot the confusion matrix in a grid for easier visualization.\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', export_as='confusion_matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    # print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True labels', fontsize=14)\n",
    "    plt.xlabel('Predicted labels', fontsize=14)\n",
    "\n",
    "    # Exporting plot image in PNG format.\n",
    "    plt.savefig(f'./output/{export_as}.png', bbox_inches='tight')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Define class labels\n",
    "cm_plot_labels = ['1-2', '3-5', '6-8', '9-12', '13-17', '18-24', '25-34', \n",
    "                  '35-44', '45-54', '55-64', '65-74', '75-84', '85+']\n",
    "\n",
    "# Loop through all models\n",
    "for i, entry in enumerate(model_list):\n",
    "    model_name = entry[\"name\"]\n",
    "    \n",
    "    \n",
    "    # best_model_path = entry[\"best_model_path\"]\n",
    "    best_model_path = f\"saved_models_config_{config_count}/{model_name}_best_model.keras\"\n",
    "    test_dataset = entry['test_data']\n",
    "\n",
    "    print(f\"🔍 Evaluating Confusion Matrix for: {model_name}\")\n",
    "\n",
    "    # Load the best saved model\n",
    "    model = load_model(best_model_path)\n",
    "\n",
    "    # Predict class probabilities\n",
    "    model_pred_probs = model.predict(test_dataset)\n",
    "    model_pred = model_pred_probs.argmax(axis=-1)\n",
    "    y_pred, y_true = get_preds_and_labels(model, test_dataset)\n",
    "\n",
    "    # y_true = dict_for_data[\"test\"][\"labels_regr\"]\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    if entry[\"task\"]==\"classification\":\n",
    "        if len(y_true.shape) > 1 and y_true.shape[1] > 1:  # One-hot check\n",
    "            y_true = np.argmax(y_true, axis=-1)\n",
    "\n",
    "        conf_mat = confusion_matrix(y_true, model_pred)\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plot_confusion_matrix(\n",
    "            conf_mat,\n",
    "            cm_plot_labels,\n",
    "            normalize=True,\n",
    "            title=f\"Confusion Matrix - {model_name}\",\n",
    "            export_as=None  # Change to f\"{model_name}_confmat\" to save\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "    print(\"Sample predictions vs actuals:\")\n",
    "    for pred, true in zip(y_pred[:10], y_true[:10]):\n",
    "        print(f\"Pred: {pred} — True: {true}\")\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_true\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
