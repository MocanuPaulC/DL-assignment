{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T21:56:16.092858Z",
     "start_time": "2025-04-01T21:55:58.498236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "import os\n",
    "\n",
    "# Create shared SQLite study\n",
    "study_name = \"multi_gpu_optuna_study\"\n",
    "storage_url = \"sqlite:///optuna_multi_gpu.db\"\n",
    "\n",
    "try:\n",
    "    optuna.create_study(study_name=study_name, direction='maximize', storage=storage_url)\n",
    "except optuna.exceptions.DuplicatedStudyError:\n",
    "    pass\n",
    "\n",
    "# Detect available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "n_trials_per_gpu = 25  # Or more\n",
    "\n",
    "# Spawn one subprocess per GPU\n",
    "processes = []\n",
    "for gpu_id in range(len(gpus)):\n",
    "    cmd = [\n",
    "        \"python\", \"optuna_worker.py\",\n",
    "        str(gpu_id),\n",
    "        str(n_trials_per_gpu),\n",
    "        study_name,\n",
    "        storage_url\n",
    "    ]\n",
    "    print(\"Launching:\", \" \".join(cmd))\n",
    "    p = subprocess.Popen(cmd)\n",
    "    processes.append(p)\n",
    "\n",
    "# Wait for all workers to finish\n",
    "for p in processes:\n",
    "    p.wait()\n"
   ],
   "id": "d7f7aead24cabdb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching: python optuna_worker.py 0 25 multi_gpu_optuna_study sqlite:///optuna_multi_gpu.db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 22:56:05.179291: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-04-01 22:56:05.179318: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-04-01 22:56:05.179324: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-04-01 22:56:05.179338: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-01 22:56:05.179346: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-04-01 22:56:06.135145: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "[W 2025-04-01 22:56:15,938] Trial 2 failed with parameters: {'batch_size': 32, 'channels': 1, 'num_conv_layers': 5, 'base_filters': 64, 'kernel_size': 3, 'activation': 'relu', 'use_skip': False, 'num_dense_layers': 2, 'dense_units': 128, 'dropout_rate': 0.3, 'output_activation': 'sigmoid', 'pool_size': 2} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/part_1/optuna_worker.py\", line 89, in objective\n",
      "    history = model.fit(\n",
      "              ^^^^^^^^^^\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
      "    logs = self.train_function(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n",
      "    if not opt_outputs.has_value():\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/tensorflow/python/data/ops/optional_ops.py\", line 176, in has_value\n",
      "    return gen_optional_ops.optional_has_value(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/tensorflow/python/ops/gen_optional_ops.py\", line 172, in optional_has_value\n",
      "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-01 22:56:15,943] Trial 2 failed with value None.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/part_1/optuna_worker.py\", line 116, in <module>\n",
      "    study.optimize(objective_wrapper(gpu_id), n_trials=n_trials)\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/optuna/study/study.py\", line 475, in optimize\n",
      "    _optimize(\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 63, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 160, in _optimize_sequential\n",
      "    frozen_trial = _run_trial(study, func, catch)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 248, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/part_1/optuna_worker.py\", line 89, in objective\n",
      "    history = model.fit(\n",
      "              ^^^^^^^^^^\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
      "    logs = self.train_function(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n",
      "    if not opt_outputs.has_value():\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/tensorflow/python/data/ops/optional_ops.py\", line 176, in has_value\n",
      "    return gen_optional_ops.optional_has_value(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bytedance/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/tensorflow/python/ops/gen_optional_ops.py\", line 172, in optional_has_value\n",
      "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 35\u001B[39m\n\u001B[32m     33\u001B[39m \u001B[38;5;66;03m# Wait for all workers to finish\u001B[39;00m\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m processes:\n\u001B[32m---> \u001B[39m\u001B[32m35\u001B[39m     \u001B[43mp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:1264\u001B[39m, in \u001B[36mPopen.wait\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m   1262\u001B[39m     endtime = _time() + timeout\n\u001B[32m   1263\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1264\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1265\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[32m   1266\u001B[39m     \u001B[38;5;66;03m# https://bugs.python.org/issue25942\u001B[39;00m\n\u001B[32m   1267\u001B[39m     \u001B[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001B[39;00m\n\u001B[32m   1268\u001B[39m     \u001B[38;5;66;03m# exit under the common assumption that it also received the ^C\u001B[39;00m\n\u001B[32m   1269\u001B[39m     \u001B[38;5;66;03m# generated SIGINT and will exit rapidly.\u001B[39;00m\n\u001B[32m   1270\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:2053\u001B[39m, in \u001B[36mPopen._wait\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m   2051\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.returncode \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2052\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m  \u001B[38;5;66;03m# Another thread waited.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2053\u001B[39m (pid, sts) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_try_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   2054\u001B[39m \u001B[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001B[39;00m\n\u001B[32m   2055\u001B[39m \u001B[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001B[39;00m\n\u001B[32m   2056\u001B[39m \u001B[38;5;66;03m# http://bugs.python.org/issue14396.\u001B[39;00m\n\u001B[32m   2057\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m pid == \u001B[38;5;28mself\u001B[39m.pid:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:2011\u001B[39m, in \u001B[36mPopen._try_wait\u001B[39m\u001B[34m(self, wait_flags)\u001B[39m\n\u001B[32m   2009\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001B[39;00m\n\u001B[32m   2010\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2011\u001B[39m     (pid, sts) = \u001B[43mos\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwaitpid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwait_flags\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2012\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mChildProcessError\u001B[39;00m:\n\u001B[32m   2013\u001B[39m     \u001B[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001B[39;00m\n\u001B[32m   2014\u001B[39m     \u001B[38;5;66;03m# for child processes has otherwise been disabled for our\u001B[39;00m\n\u001B[32m   2015\u001B[39m     \u001B[38;5;66;03m# process.  This child is dead, we can't get the status.\u001B[39;00m\n\u001B[32m   2016\u001B[39m     pid = \u001B[38;5;28mself\u001B[39m.pid\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
