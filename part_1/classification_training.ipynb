{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T16:27:47.495376Z",
     "start_time": "2025-04-01T16:27:43.584345Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 19:57:29.589231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743537449.607356    6882 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743537449.612996    6882 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743537449.626444    6882 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743537449.626461    6882 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743537449.626463    6882 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743537449.626465    6882 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-01 19:57:29.631248: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "import shutil\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to sys.path\n",
    "parent_dir = Path(\"..\").resolve()\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "import importlib\n",
    "import common_utils\n",
    "importlib.reload(common_utils)\n",
    "\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "\n",
    "from common_utils import (\n",
    "    get_unique_image_shapes,\n",
    "    get_unique_image_paths,\n",
    "    load_images_from_paths,\n",
    "    build_image_dataframe,\n",
    "    split_data,\n",
    "    bin_ages,\n",
    "    build_cnn_model,\n",
    "    build_model_from_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b449a3fa11f15cff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T16:27:47.505672Z",
     "start_time": "2025-04-01T16:27:47.496286Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5acada596262b76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T16:27:47.516108Z",
     "start_time": "2025-04-01T16:27:47.506352Z"
    }
   },
   "outputs": [],
   "source": [
    "image_paths_csv = pd.read_csv('./processed_data/image_paths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6164dda010f022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T16:27:47.519887Z",
     "start_time": "2025-04-01T16:27:47.517146Z"
    }
   },
   "outputs": [],
   "source": [
    "paths_train_df, paths_val_df, paths_test_df = split_data(image_paths_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c9e2ceb3a1f9176",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T16:27:47.527273Z",
     "start_time": "2025-04-01T16:27:47.520343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>age</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>age_bin_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../raw_data2/face_age/040/7094.png</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>Mid Adults (35–44)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../raw_data2/face_age/026/2249.png</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>Adults (25–34)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../raw_data2/face_age/015/2507.png</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>Teens (13–17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../raw_data2/face_age/019/2581.png</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>Young Adults (18–24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../raw_data2/face_age/059/2622.png</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>Older Adults (55–64)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6887</th>\n",
       "      <td>../raw_data2/face_age/002/4416.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Infants (1–2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6888</th>\n",
       "      <td>../raw_data2/face_age/025/9562.png</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>Adults (25–34)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>../raw_data2/face_age/068/897.png</td>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "      <td>Seniors (65–74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6890</th>\n",
       "      <td>../raw_data2/face_age/039/6046.png</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>Mid Adults (35–44)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6891</th>\n",
       "      <td>../raw_data2/face_age/021/5046.png</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>Young Adults (18–24)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6892 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    path  age  age_bin         age_bin_label\n",
       "0     ../raw_data2/face_age/040/7094.png   40        7    Mid Adults (35–44)\n",
       "1     ../raw_data2/face_age/026/2249.png   26        6        Adults (25–34)\n",
       "2     ../raw_data2/face_age/015/2507.png   15        4         Teens (13–17)\n",
       "3     ../raw_data2/face_age/019/2581.png   19        5  Young Adults (18–24)\n",
       "4     ../raw_data2/face_age/059/2622.png   59        9  Older Adults (55–64)\n",
       "...                                  ...  ...      ...                   ...\n",
       "6887  ../raw_data2/face_age/002/4416.png    2        0         Infants (1–2)\n",
       "6888  ../raw_data2/face_age/025/9562.png   25        6        Adults (25–34)\n",
       "6889   ../raw_data2/face_age/068/897.png   68       10       Seniors (65–74)\n",
       "6890  ../raw_data2/face_age/039/6046.png   39        7    Mid Adults (35–44)\n",
       "6891  ../raw_data2/face_age/021/5046.png   21        5  Young Adults (18–24)\n",
       "\n",
       "[6892 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42e398f76e04c83c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T16:27:47.544555Z",
     "start_time": "2025-04-01T16:27:47.527940Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743537452.102455    6882 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43622 MB memory:  -> device: 0, name: NVIDIA L40S, pci bus id: 0000:81:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Converting the filenames and target class labels into lists for augmented train and test datasets.\n",
    "\n",
    "train_filenames_list = list(paths_train_df['path'])\n",
    "train_labels_list = list(paths_train_df['age_bin'])\n",
    "\n",
    "train_filenames_tensor = tf.constant(train_filenames_list)\n",
    "train_labels_tensor = tf.constant(train_labels_list)\n",
    "\n",
    "val_filenames_list = list(paths_val_df['path'])\n",
    "val_labels_list = list(paths_val_df['age_bin'])\n",
    "\n",
    "val_filenames_tensor = tf.constant(val_filenames_list)\n",
    "val_labels_tensor = tf.constant(val_labels_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "581a5c16afb90f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T16:27:47.546315Z",
     "start_time": "2025-04-01T16:27:47.545146Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77f27c3567505cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T16:27:47.548619Z",
     "start_time": "2025-04-01T16:27:47.546764Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "configurations = {\n",
    "    'channels': [1,3],\n",
    "    'num_conv_layers': [3,4],\n",
    "    'base_filters': [32,64],\n",
    "    'kernel_size': [3,5],\n",
    "    'activation': ['relu','swish'],\n",
    "    'use_skip': [False,True],\n",
    "    'num_dense_layers': [1,2],\n",
    "    'dense_units': [128,256],\n",
    "    'num_classes': [13],\n",
    "    'dropout_rate': [0.3, 0.5],\n",
    "    'output_activation': ['softmax','sigmoid'],\n",
    "    'pool_size': [2],\n",
    "    'task': ['classification']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca3121863a1d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e736c21984667af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T16:27:47.550831Z",
     "start_time": "2025-04-01T16:27:47.549137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr of combinations : %d 1024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_combinations = list(itertools.product(*configurations.values()))\n",
    "print(f\"nr of combinations : %d\", len(all_combinations))\n",
    "valid_configs = []\n",
    "\n",
    "for combo in all_combinations:\n",
    "    params = dict(zip(configurations.keys(), combo))\n",
    "    \n",
    "    # Enforce: If use_skip=True, use_pooling=False\n",
    "    if params['use_skip']:\n",
    "        params['use_pooling'] = False\n",
    "    else:\n",
    "        params['use_pooling'] = True  # Or add to search space\n",
    "    \n",
    "    valid_configs.append(params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c148d5e8b1c8ddb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T16:27:47.595752Z",
     "start_time": "2025-04-01T16:27:47.553874Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = load_images_from_paths(train_filenames_tensor,train_labels_tensor, channels=3,ratio=1, batch_size=batch_size)\n",
    "val_dataset = load_images_from_paths(val_filenames_tensor,val_labels_tensor, channels=3,ratio=1,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f3b6c2badd58277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-01 19:57:32,846] A new study created in memory with name: no-name-9477703c-f0a8-4788-aed5-07776c84ed24\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743537456.205973    7991 service.cc:152] XLA service 0x7ef9ac005190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743537456.206019    7991 service.cc:160]   StreamExecutor device (0): NVIDIA L40S, Compute Capability 8.9\n",
      "2025-04-01 19:57:36.312854: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743537456.720421    7991 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-04-01 19:57:41.816273: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1365', 120 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "2025-04-01 19:57:41.846044: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1365', 468 bytes spill stores, 468 bytes spill loads\n",
      "\n",
      "2025-04-01 19:57:41.853132: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2788', 116 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "2025-04-01 19:57:41.882655: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1365', 2936 bytes spill stores, 2940 bytes spill loads\n",
      "\n",
      "2025-04-01 19:57:41.924980: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2788', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "2025-04-01 19:57:41.976174: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1365', 584 bytes spill stores, 584 bytes spill loads\n",
      "\n",
      "2025-04-01 19:57:42.162252: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2790', 720 bytes spill stores, 1216 bytes spill loads\n",
      "\n",
      "2025-04-01 19:57:42.294393: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2790', 524 bytes spill stores, 1100 bytes spill loads\n",
      "\n",
      "2025-04-01 19:57:42.485546: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1365_0', 692 bytes spill stores, 2152 bytes spill loads\n",
      "\n",
      "2025-04-01 19:57:42.826163: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1365_0', 2420 bytes spill stores, 4184 bytes spill loads\n",
      "\n",
      "2025-04-01 19:57:48.859991: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bias-activation.54 = (f32[128,128,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,64,200,200]{3,2,1,0} %bitcast.15027, f32[128,64,7,7]{3,2,1,0} %bitcast.14872, f32[128]{0} %bitcast.14909), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_2_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:57:50.963698: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.103820212s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv-bias-activation.54 = (f32[128,128,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,64,200,200]{3,2,1,0} %bitcast.15027, f32[128,64,7,7]{3,2,1,0} %bitcast.14872, f32[128]{0} %bitcast.14909), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_2_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:57:54.579247: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=15,k6=2,k13=0,k14=0,k22=0} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:57:55.051489: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.472326422s\n",
      "Trying algorithm eng33{k2=15,k6=2,k13=0,k14=0,k22=0} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:57:56.051618: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng20{k2=1,k4=2,k5=1,k6=0,k7=0,k19=0} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:57:56.570181: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.518633455s\n",
      "Trying algorithm eng20{k2=1,k4=2,k5=1,k6=0,k7=0,k19=0} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:57:57.570290: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=0,k3=0} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:57:58.318855: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.748634682s\n",
      "Trying algorithm eng11{k2=0,k3=0} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:57:59.319015: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=0,k13=2,k14=0,k22=2} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:57:59.990059: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.671161866s\n",
      "Trying algorithm eng33{k2=2,k6=0,k13=2,k14=0,k22=2} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:00.990198: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=1,k3=0} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:01.502108: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.512012354s\n",
      "Trying algorithm eng11{k2=1,k3=0} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:02.502287: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=3,k3=0} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:04.182059: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.679911353s\n",
      "Trying algorithm eng11{k2=3,k3=0} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:05.182222: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=4,k3=0} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:06.962162: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.780060516s\n",
      "Trying algorithm eng11{k2=4,k3=0} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:07.962302: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:19.529733: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 12.56751281s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv-bias-activation.56 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,7,7]{3,2,1,0} %bitcast.15080, f32[256]{0} %bitcast.15117), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_4_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:22.789696: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bias-activation.57 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,1,1]{3,2,1,0} %bitcast.15219, f32[256]{0} %bitcast.15256, f32[128,256,200,200]{3,2,1,0} %bitcast.13694), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_5_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":1,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:22.797673: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.008080911s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv-bias-activation.57 = (f32[128,256,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,128,200,200]{3,2,1,0} %bitcast.15235, f32[256,128,1,1]{3,2,1,0} %bitcast.15219, f32[256]{0} %bitcast.15256, f32[128,256,200,200]{3,2,1,0} %bitcast.13694), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_5_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":1,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:23.800703: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng13{} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:23.929662: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.129050604s\n",
      "Trying algorithm eng13{} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:24.929828: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=2,k13=1,k14=0,k22=0} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:27.621828: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.692120993s\n",
      "Trying algorithm eng33{k2=2,k6=2,k13=1,k14=0,k22=0} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:28.621965: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=15,k6=2,k13=0,k14=0,k22=0} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:33.283442: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 5.661563882s\n",
      "Trying algorithm eng33{k2=15,k6=2,k13=0,k14=0,k22=0} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:34.283560: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng20{k2=1,k4=2,k5=1,k6=0,k7=0,k19=0} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:39.407136: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 6.12364735s\n",
      "Trying algorithm eng20{k2=1,k4=2,k5=1,k6=0,k7=0,k19=0} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:40.407255: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=0,k13=2,k14=0,k22=2} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:45.779830: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 6.372634035s\n",
      "Trying algorithm eng33{k2=2,k6=0,k13=2,k14=0,k22=2} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:46.780012: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=1,k3=0} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:51.796698: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 6.016754266s\n",
      "Trying algorithm eng11{k2=1,k3=0} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:52.796882: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=0,k3=0} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:58:58.860642: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 7.063832382s\n",
      "Trying algorithm eng11{k2=0,k3=0} for conv %cudnn-conv-bias-activation.58 = (f32[128,512,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,200,200]{3,2,1,0} %bitcast.15443, f32[512,256,7,7]{3,2,1,0} %bitcast.15288, f32[512]{0} %bitcast.15325), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:59:00.939850: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 11.92GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-01 19:59:01.884559: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 11.92GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-01 19:59:01.884585: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 11.92GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-01 19:59:01.884611: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 11.92GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-01 19:59:03.459314: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=2,k13=1,k14=0,k22=0} for conv %cudnn-conv-bias-activation.60 = (f32[128,1024,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,512,200,200]{3,2,1,0} %bitcast.15651, f32[1024,512,7,7]{3,2,1,0} %bitcast.15496, f32[1024]{0} %bitcast.15533), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_8_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:59:19.832222: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 19.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-01 19:59:19.832254: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 17.373029338s\n",
      "Trying algorithm eng33{k2=2,k6=2,k13=1,k14=0,k22=0} for conv %cudnn-conv-bias-activation.60 = (f32[128,1024,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,512,200,200]{3,2,1,0} %bitcast.15651, f32[1024,512,7,7]{3,2,1,0} %bitcast.15496, f32[1024]{0} %bitcast.15533), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_8_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-01 19:59:19.929036: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.60 = (f32[128,1024,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,512,200,200]{3,2,1,0} %bitcast.15651, f32[1024,512,7,7]{3,2,1,0} %bitcast.15496, f32[1024]{0} %bitcast.15533), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_8_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20988297216 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "2025-04-01 19:59:19.929393: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.60 = (f32[128,1024,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,512,200,200]{3,2,1,0} %bitcast.15651, f32[1024,512,7,7]{3,2,1,0} %bitcast.15496, f32[1024]{0} %bitcast.15533), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_8_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20988297216 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n",
      "[W 2025-04-01 19:59:19,935] Trial 0 failed with parameters: {'batch_size': 128, 'channels': 3, 'num_conv_layers': 5, 'base_filters': 64, 'kernel_size': 7, 'activation': 'relu', 'use_skip': True, 'num_dense_layers': 3, 'dense_units': 128, 'dropout_rate': 0.5, 'output_activation': 'sigmoid', 'pool_size': 3} because of the following error: UnknownError().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_6882/726633106.py\", line 64, in objective\n",
      "    history = model.fit(\n",
      "              ^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    except TypeError as e:\n",
      "tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n",
      "\n",
      "Detected at node StatefulPartitionedCall defined at (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "\n",
      "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "\n",
      "  File \"/tmp/ipykernel_6882/726633106.py\", line 91, in <module>\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\", line 475, in optimize\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 63, in _optimize\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 160, in _optimize_sequential\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "\n",
      "  File \"/tmp/ipykernel_6882/726633106.py\", line 64, in objective\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n",
      "\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n",
      "\n",
      "Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.60 = (f32[128,1024,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,512,200,200]{3,2,1,0} %bitcast.15651, f32[1024,512,7,7]{3,2,1,0} %bitcast.15496, f32[1024]{0} %bitcast.15533), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_8_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20988297216 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_5372]\n",
      "[W 2025-04-01 19:59:19,937] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_6882/726633106.py\", line 91, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\", line 475, in optimize\n\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 63, in _optimize\n\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 160, in _optimize_sequential\n\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n\n  File \"/tmp/ipykernel_6882/726633106.py\", line 64, in objective\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.60 = (f32[128,1024,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,512,200,200]{3,2,1,0} %bitcast.15651, f32[1024,512,7,7]{3,2,1,0} %bitcast.15496, f32[1024]{0} %bitcast.15533), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_8_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20988297216 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_5372]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 91\u001b[0m\n\u001b[1;32m     87\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# n_trials defines how many different hyperparameter configurations will be evaluated.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Here it's set to 10 for demonstration. In practice, you might increase this number to explore the search space more thoroughly.\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(study\u001b[38;5;241m.\u001b[39mtrials, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: t\u001b[38;5;241m.\u001b[39mvalue, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:\u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m     94\u001b[0m best_models_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_models\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[10], line 64\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     59\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m load_images_from_paths(val_filenames_tensor, val_labels_tensor,\n\u001b[1;32m     60\u001b[0m                                      channels\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels\u001b[39m\u001b[38;5;124m'\u001b[39m], ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     61\u001b[0m                                      batch_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Train the model with early stopping.\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m  \u001b[38;5;66;03m# Save the trained model to disk.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_models\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_6882/726633106.py\", line 91, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\", line 475, in optimize\n\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 63, in _optimize\n\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 160, in _optimize_sequential\n\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n\n  File \"/tmp/ipykernel_6882/726633106.py\", line 64, in objective\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.60 = (f32[128,1024,200,200]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,512,200,200]{3,2,1,0} %bitcast.15651, f32[1024,512,7,7]{3,2,1,0} %bitcast.15496, f32[1024]{0} %bitcast.15533), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_8_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20988297216 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_5372]"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Assume these functions are defined elsewhere:\n",
    "# - load_images_from_paths(filenames, labels, channels, ratio, batch_size)\n",
    "# - build_model_from_config(config)\n",
    "#\n",
    "# Also assume that the following dataset variables are defined:\n",
    "# train_filenames_tensor, train_labels_tensor, val_filenames_tensor, val_labels_tensor\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters using Optuna suggestions.\n",
    "    config = {\n",
    "        'batch_size': trial.suggest_categorical('batch_size',[32,64,128,256]),  \n",
    "        'channels': trial.suggest_categorical('channels', [1, 3]),\n",
    "        'num_conv_layers': trial.suggest_categorical('num_conv_layers', [3, 4, 5]),\n",
    "        'base_filters': trial.suggest_categorical('base_filters', [32, 64, 128]),\n",
    "        'kernel_size': trial.suggest_categorical('kernel_size', [3, 5, 7]),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'swish']),\n",
    "        'use_skip': trial.suggest_categorical('use_skip', [False, True]),\n",
    "        'num_dense_layers': trial.suggest_categorical('num_dense_layers', [1, 2, 3]),\n",
    "        'dense_units': trial.suggest_categorical('dense_units', [128, 256]),\n",
    "        'num_classes': 13,  # Fixed\n",
    "        'dropout_rate': trial.suggest_categorical('dropout_rate', [0.3, 0.5, 0.7]),\n",
    "        'output_activation': trial.suggest_categorical('output_activation', ['softmax', 'sigmoid']),\n",
    "        'pool_size': trial.suggest_categorical('pool_size', [2, 3]),\n",
    "        'task': 'classification',\n",
    "    }\n",
    "    \n",
    "    # Enforce: If use_skip=True, then use_pooling is False; otherwise, True.\n",
    "    config['use_pooling'] = False if config['use_skip'] else True\n",
    "\n",
    "    # Generate a model name from the configuration for logging.\n",
    "    model_name = \"_\".join([\n",
    "        f\"{config['channels']}ch\",\n",
    "        f\"skip_{config['use_skip']}\",\n",
    "        f\"conv{config['num_conv_layers']}\",\n",
    "        f\"k{config['kernel_size']}\",\n",
    "        config['activation'],\n",
    "        f\"dense{config['num_dense_layers']}x{config['dense_units']}\",\n",
    "        f\"drop{config['dropout_rate']}\",\n",
    "        f\"out_{config['output_activation']}\"\n",
    "    ])\n",
    "    trial.set_user_attr('model_name', model_name)\n",
    "\n",
    "    # Build the model from the configuration.\n",
    "    model = build_model_from_config(config)\n",
    "    model.compile(\n",
    "        optimizer='lion',\n",
    "        loss='categorical_crossentropy',  # Fixed loss function.\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Load datasets using the specified channels and batch_size.\n",
    "    train_dataset = load_images_from_paths(train_filenames_tensor, train_labels_tensor,\n",
    "                                           channels=config['channels'], ratio=1,\n",
    "                                           batch_size=config['batch_size'])\n",
    "    val_dataset = load_images_from_paths(val_filenames_tensor, val_labels_tensor,\n",
    "                                         channels=config['channels'], ratio=1,\n",
    "                                         batch_size=config['batch_size'])\n",
    "\n",
    "    # Train the model with early stopping.\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=50,\n",
    "        verbose=0,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "    )\n",
    "\n",
    "     # Save the trained model to disk.\n",
    "    model_dir = \"saved_models\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_filename = f\"{model_name}_trial_{trial.number}.keras\"\n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "    model.save(model_path)\n",
    "    \n",
    "    trial.set_user_attr('model_path', model_path)\n",
    "    \n",
    "    val_acc = max(history.history['val_accuracy'])\n",
    "    print(f\"Trial {trial.number} | Model: {model_name} | Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    return val_acc\n",
    "    \n",
    "    \n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# n_trials defines how many different hyperparameter configurations will be evaluated.\n",
    "# Here it's set to 10 for demonstration. In practice, you might increase this number to explore the search space more thoroughly.\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_trials = sorted(study.trials, key=lambda t: t.value, reverse=True)[:10]\n",
    "best_models_dir = \"best_models\"\n",
    "os.makedirs(best_models_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\nSaving best models:\")\n",
    "for trial in best_trials:\n",
    "    model_path = trial.user_attrs.get('model_path')\n",
    "    model_name = trial.user_attrs.get('model_name')\n",
    "    if model_path and os.path.exists(model_path):\n",
    "        dest_path = os.path.join(best_models_dir, os.path.basename(model_path))\n",
    "        shutil.copy(model_path, dest_path)\n",
    "        print(f\"Saved {model_name} with Val Acc: {trial.value:.4f} to {dest_path}\")\n",
    "\n",
    "# Display the best trial's results.\n",
    "best_trial = study.best_trial\n",
    "print(\"\\nBest trial:\")\n",
    "print(f\"  Model: {best_trial.user_attrs['model_name']}\")\n",
    "print(f\"  Validation Accuracy: {best_trial.value:.4f}\")\n",
    "print(\"  Hyperparameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec404ce8136a4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-01T16:27:47.600090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cast (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,924</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,729</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cast (\u001b[38;5;33mCast\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m)            │        \u001b[38;5;34m33,924\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │         \u001b[38;5;34m1,729\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">408,261</span> (1.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m408,261\u001b[0m (1.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,365</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,365\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 17:27:48.351644: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 - 117s - 1s/step - accuracy: 0.2073 - loss: 2.4318 - val_accuracy: 0.1706 - val_loss: 2.6611\n",
      "Epoch 2/50\n"
     ]
    }
   ],
   "source": [
    "# model_dict = {}\n",
    "# model_dir = \"saved_models\"\n",
    "# os.makedirs(model_dir, exist_ok=True)\n",
    "# paths_pre_train_model_dict = {}\n",
    "# \n",
    "# \n",
    "# for i, config in enumerate(valid_configs):\n",
    "#     # Generate unique model name\n",
    "#     name_parts = [\n",
    "#         f\"{config['channels']}ch\",\n",
    "#         f\"skip_{config['use_skip']}\",\n",
    "#         f\"conv{config['num_conv_layers']}\",\n",
    "#         f\"k{config['kernel_size']}\",\n",
    "#         config['activation'],\n",
    "#         f\"dense{config['num_dense_layers']}x{config['dense_units']}\",\n",
    "#         f\"drop{config['dropout_rate']}\",\n",
    "#         f\"out_{config['output_activation']}\"\n",
    "#     ]\n",
    "#     \n",
    "#     model_name = \"_\".join(name_parts)\n",
    "#     # model_filename = model_name + \".keras\"\n",
    "#     # model_path = os.path.join(model_dir, model_filename)\n",
    "# \n",
    "#     # Build and compile\n",
    "#     model = build_model_from_config(config)\n",
    "#     model.compile(\n",
    "#         optimizer='adam',\n",
    "#         loss='categorical_crossentropy',  # Fixed loss function\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "#     # model.save(model_path,overwrite=True)\n",
    "#     # model.summary()\n",
    "#     # paths_pre_train_model_dict[model_name] = {\n",
    "#     #     'model_path': model_path,\n",
    "#     #     'config': config\n",
    "#     # }\n",
    "#     # \n",
    "#     # # Train\n",
    "#     history = model.fit(\n",
    "#         train_dataset,  # Dataset yields (images, targets)\n",
    "#         validation_data=val_dataset,\n",
    "#         epochs=50,\n",
    "#         batch_size=batch_size,\n",
    "#         verbose=2,\n",
    "#         callbacks=[tf.keras.callbacks.EarlyStopping(patience=10)]\n",
    "#     )\n",
    "# \n",
    "#     # Store results\n",
    "#     model_dict[model_name] = {\n",
    "#         'model': model,\n",
    "#         'history': history.history,\n",
    "#         'config': config\n",
    "#     }\n",
    "#     print(f\"Trained {model_name} | Val acc: {max(history.history['val_accuracy']):.4f}\")\n",
    "#     # print(f\"Created {model_name} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfb41fdac8151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict['1ch_skip_False_conv3_k3_relu_dense1x132_out_softmax']['history']['accuracy']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
