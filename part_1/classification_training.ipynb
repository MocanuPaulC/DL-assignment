{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-01T00:04:24.826216Z",
     "start_time": "2025-04-01T00:04:23.403455Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "import importlib\n",
    "import common_utils\n",
    "importlib.reload(common_utils)\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "from common_utils import get_unique_image_shapes,get_unique_image_paths,load_images_from_paths,build_image_dataframe,split_data, bin_ages, build_cnn_model,build_model_from_config"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 02:04:23.736526: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-01 02:04:23.746167: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743465863.757078   80061 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743465863.760255   80061 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743465863.769127   80061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743465863.769136   80061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743465863.769137   80061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743465863.769138   80061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-01 02:04:23.771848: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:04:24.980932Z",
     "start_time": "2025-04-01T00:04:24.830043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n"
   ],
   "id": "b449a3fa11f15cff",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:04:25.066954Z",
     "start_time": "2025-04-01T00:04:25.057717Z"
    }
   },
   "cell_type": "code",
   "source": "image_paths_csv = pd.read_csv('./processed_data/image_paths.csv')",
   "id": "a5acada596262b76",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:04:25.109376Z",
     "start_time": "2025-04-01T00:04:25.103638Z"
    }
   },
   "cell_type": "code",
   "source": "paths_train_df, paths_val_df, paths_test_df = split_data(image_paths_csv)",
   "id": "e6164dda010f022",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:04:25.154921Z",
     "start_time": "2025-04-01T00:04:25.152340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "configurations = {\n",
    "    'channels': [3],\n",
    "    'use_skip': [True, False],\n",
    "    'num_conv_layers': [3, 4,],\n",
    "    'base_filters': [16,32, 64],\n",
    "    'kernel_size': [3, 5,7],\n",
    "    'activation': ['relu', 'elu','leakyrelu','tanh','swish'],\n",
    "    'num_dense_layers': [1, 2,3,4],\n",
    "    'dense_units': [128, 256],\n",
    "    'dropout_rate': [0.3, 0.5,0.7],\n",
    "    'output_activation': ['sigmoid', 'softmax'],\n",
    "}\n"
   ],
   "id": "f77f27c3567505cf",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:04:25.207838Z",
     "start_time": "2025-04-01T00:04:25.198671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "all_combinations = list(itertools.product(*configurations.values()))\n",
    "valid_configs = []\n",
    "\n",
    "for combo in all_combinations:\n",
    "    params = dict(zip(configurations.keys(), combo))\n",
    "    \n",
    "    # Enforce: If use_skip=True, use_pooling=False\n",
    "    if params['use_skip']:\n",
    "        params['use_pooling'] = False\n",
    "    else:\n",
    "        params['use_pooling'] = True  # Or add to search space\n",
    "    \n",
    "    valid_configs.append(params)\n",
    "\n"
   ],
   "id": "e736c21984667af3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:04:25.441782Z",
     "start_time": "2025-04-01T00:04:25.254294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = load_images_from_paths(paths_train_df, channels=3,ratio=0.1)\n",
    "val_dataset = load_images_from_paths(paths_val_df, channels=3,ratio=0.1)\n"
   ],
   "id": "c148d5e8b1c8ddb9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743465865.369970   80061 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1743465865.371261   80061 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6172 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:04:25.454003Z",
     "start_time": "2025-04-01T00:04:25.452042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def configure_dataset(dataset, shuffle=False):\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=1000)  # Adjust buffer size as needed\n",
    "    dataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n"
   ],
   "id": "fc46df10f99cd492",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:04:25.510334Z",
     "start_time": "2025-04-01T00:04:25.496128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = configure_dataset(train_dataset, shuffle=True)\n",
    "val_dataset = configure_dataset(val_dataset)\n"
   ],
   "id": "b9aa26f54d02a548",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:04:25.544190Z",
     "start_time": "2025-04-01T00:04:25.542248Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8c6cd364482f42a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T00:05:21.031640Z",
     "start_time": "2025-04-01T00:04:25.587995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dict = {}\n",
    "\n",
    "for i, config in enumerate(valid_configs):  # Limit to 10 for demo\n",
    "    # Generate unique model name (your existing code)\n",
    "    name_parts = [\n",
    "        f\"{config['channels']}ch\",\n",
    "        f\"skip_{config['use_skip']}\",\n",
    "        f\"conv{config['num_conv_layers']}\",\n",
    "        f\"k{config['kernel_size']}\",\n",
    "        config['activation'],\n",
    "        f\"dense{config['num_dense_layers']}x{config['dense_units']}\",\n",
    "        f\"drop{config['dropout_rate']}\",\n",
    "        f\"out_{config['output_activation']}\"\n",
    "    ]\n",
    "    model_name = \"_\".join(name_parts)\n",
    "    \n",
    "    # Build and compile\n",
    "    model = build_model_from_config(config)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',  # Fixed loss function\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    \n",
    "        # Train\n",
    "    history = model.fit(\n",
    "        train_dataset,  # Dataset yields (images, targets)\n",
    "        validation_data=val_dataset,\n",
    "        epochs=50,\n",
    "        batch_size=8,\n",
    "        verbose=0,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)]\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    model_dict[model_name] = {\n",
    "        'model': model,\n",
    "        'history': history.history,\n",
    "        'config': config\n",
    "    }\n",
    "    print(f\"Trained {model_name} | Val acc: {max(history.history['val_accuracy']):.4f}\")\n"
   ],
   "id": "83ec404ce8136a4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743465867.827724   80171 service.cc:152] XLA service 0x70a484006da0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743465867.827742   80171 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Laptop GPU, Compute Capability 8.6\n",
      "2025-04-01 02:04:27.869133: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743465868.218427   80171 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1743465874.782813   80171 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-04-01 02:04:40.347255: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_150', 244 bytes spill stores, 244 bytes spill loads\n",
      "\n",
      "2025-04-01 02:04:42.285271: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_150', 228 bytes spill stores, 228 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 3ch_skip_True_conv3_k3_relu_dense1x128_drop0.3_out_sigmoid | Val acc: 0.1395\n",
      "Trained 3ch_skip_True_conv3_k3_relu_dense1x128_drop0.3_out_softmax | Val acc: 0.1453\n",
      "Trained 3ch_skip_True_conv3_k3_relu_dense1x128_drop0.5_out_sigmoid | Val acc: 0.2151\n",
      "Trained 3ch_skip_True_conv3_k3_relu_dense1x128_drop0.5_out_softmax | Val acc: 0.1453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 02:05:20.705936: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:359] gpu_async_0 cuMemAllocAsync failed to allocate 536870912 bytes: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      " Reported by CUDA: Free memory/Total memory: 331677696/8248885248\n",
      "2025-04-01 02:05:20.705953: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:364] Stats: Limit:                      6472138752\n",
      "InUse:                      7517671709\n",
      "MaxInUse:                   7564940341\n",
      "NumAllocs:                        7598\n",
      "MaxAllocSize:                577842224\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-04-01 02:05:20.705962: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:68] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2025-04-01 02:05:20.705963: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1, 1\n",
      "2025-04-01 02:05:20.705964: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 4, 54\n",
      "2025-04-01 02:05:20.705965: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 8, 19\n",
      "2025-04-01 02:05:20.705966: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 16, 5\n",
      "2025-04-01 02:05:20.705967: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 52, 12\n",
      "2025-04-01 02:05:20.705967: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 64, 62\n",
      "2025-04-01 02:05:20.705968: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 128, 62\n",
      "2025-04-01 02:05:20.705969: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 192, 13\n",
      "2025-04-01 02:05:20.705970: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 256, 62\n",
      "2025-04-01 02:05:20.705970: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 512, 12\n",
      "2025-04-01 02:05:20.705971: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1028, 1\n",
      "2025-04-01 02:05:20.705972: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1376, 1\n",
      "2025-04-01 02:05:20.705973: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1728, 13\n",
      "2025-04-01 02:05:20.705973: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 2048, 13\n",
      "2025-04-01 02:05:20.705974: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 5512, 1\n",
      "2025-04-01 02:05:20.705975: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 6656, 12\n",
      "2025-04-01 02:05:20.705976: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 8192, 13\n",
      "2025-04-01 02:05:20.705976: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 18432, 13\n",
      "2025-04-01 02:05:20.705977: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 73728, 13\n",
      "2025-04-01 02:05:20.705978: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 536870912, 14\n",
      "2025-04-01 02:05:20.705980: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:104] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 7717519360\n",
      "2025-04-01 02:05:20.705981: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:106] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 7517671709\n",
      "2025-04-01 02:05:20.705982: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:107] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 8019509248\n",
      "2025-04-01 02:05:20.705983: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:108] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 7564940341\n",
      "2025-04-01 02:05:20.705986: W tensorflow/core/framework/op_kernel.cc:1844] RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "2025-04-01 02:05:20.705991: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mResourceExhaustedError\u001B[39m                    Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 18\u001B[39m\n\u001B[32m     15\u001B[39m model_name = \u001B[33m\"\u001B[39m\u001B[33m_\u001B[39m\u001B[33m\"\u001B[39m.join(name_parts)\n\u001B[32m     17\u001B[39m \u001B[38;5;66;03m# Build and compile\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m model = \u001B[43mbuild_model_from_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m model.compile(\n\u001B[32m     20\u001B[39m     optimizer=\u001B[33m'\u001B[39m\u001B[33madam\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     21\u001B[39m     loss=\u001B[33m'\u001B[39m\u001B[33msparse_categorical_crossentropy\u001B[39m\u001B[33m'\u001B[39m,  \u001B[38;5;66;03m# Fixed loss function\u001B[39;00m\n\u001B[32m     22\u001B[39m     metrics=[\u001B[33m'\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     23\u001B[39m )\n\u001B[32m     26\u001B[39m     \u001B[38;5;66;03m# Train\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DL-assignment/common_utils.py:237\u001B[39m, in \u001B[36mbuild_model_from_config\u001B[39m\u001B[34m(config)\u001B[39m\n\u001B[32m    233\u001B[39m conv_filters = [config[\u001B[33m'\u001B[39m\u001B[33mbase_filters\u001B[39m\u001B[33m'\u001B[39m] * (\u001B[32m2\u001B[39m ** i)\n\u001B[32m    234\u001B[39m                 \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(config[\u001B[33m'\u001B[39m\u001B[33mnum_conv_layers\u001B[39m\u001B[33m'\u001B[39m])]\n\u001B[32m    236\u001B[39m \u001B[38;5;66;03m# Build the model\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m237\u001B[39m model = \u001B[43mbuild_cnn_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    238\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Use preprocessed input\u001B[39;49;00m\n\u001B[32m    239\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mclassification\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    240\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m13\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    241\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_conv_layers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mnum_conv_layers\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    242\u001B[39m \u001B[43m    \u001B[49m\u001B[43mconv_filters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconv_filters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    243\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mkernel_size\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    244\u001B[39m \u001B[43m    \u001B[49m\u001B[43mactivation\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mactivation\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    245\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_pooling\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43muse_pooling\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# From enforced rule\u001B[39;49;00m\n\u001B[32m    246\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_skip\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43muse_skip\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    247\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_dense_layers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mnum_dense_layers\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    248\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdense_units\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mdense_units\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mnum_dense_layers\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    249\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdropout_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mdropout_rate\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    250\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpool_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Fixed for simplicity\u001B[39;49;00m\n\u001B[32m    251\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DL-assignment/common_utils.py:204\u001B[39m, in \u001B[36mbuild_cnn_model\u001B[39m\u001B[34m(input_tensor, task, num_classes, num_conv_layers, conv_filters, kernel_size, activation, use_pooling, use_skip, num_dense_layers, dense_units, dropout_rate, pool_size)\u001B[39m\n\u001B[32m    202\u001B[39m \u001B[38;5;66;03m# Add fully connected (dense) layers\u001B[39;00m\n\u001B[32m    203\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m units \u001B[38;5;129;01min\u001B[39;00m dense_units:\n\u001B[32m--> \u001B[39m\u001B[32m204\u001B[39m     x = \u001B[43mlayers\u001B[49m\u001B[43m.\u001B[49m\u001B[43mDense\u001B[49m\u001B[43m(\u001B[49m\u001B[43munits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactivation\u001B[49m\u001B[43m=\u001B[49m\u001B[43mactivation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    205\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m dropout_rate > \u001B[32m0\u001B[39m:\n\u001B[32m    206\u001B[39m         x = layers.Dropout(dropout_rate)(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m    120\u001B[39m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DL-assignment/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/random.py:34\u001B[39m, in \u001B[36muniform\u001B[39m\u001B[34m(shape, minval, maxval, dtype, seed)\u001B[39m\n\u001B[32m     32\u001B[39m dtype = dtype \u001B[38;5;129;01mor\u001B[39;00m floatx()\n\u001B[32m     33\u001B[39m seed = _cast_seed(draw_seed(seed))\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrandom\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstateless_uniform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     35\u001B[39m \u001B[43m    \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     36\u001B[39m \u001B[43m    \u001B[49m\u001B[43mminval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mminval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmaxval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaxval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     38\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     39\u001B[39m \u001B[43m    \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m=\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     40\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mResourceExhaustedError\u001B[39m: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: "
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
